{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DoV3xwEnwXvc"
   },
   "source": [
    "\n",
    "### 1.1. Description \n",
    "\n",
    "Dans ce projet, nous allons travailler sur un système de **génération augmentée de récupération**, ou **RAG** (*Retrieval Augmented Generation* en anglais), qui combine des modèles de langue génératifs et des techniques de recherche d'information.  \n",
    "\n",
    "À partir d'une question donnée, nous devrons identifier les passages les plus pertinents à l'aide d'un modèle de recherche, puis générer une réponse en utilisant ces passages de texte. Enfin, nous explorerons différentes approches pour améliorer les performances de notre modèle RAG.  \n",
    "\n",
    "### Description des données\n",
    "\n",
    "Les passages donnés sont des textes en anglais de quelques phrases sur divers sujets. Par exemple, les mathématiques, la physique, la chimie, la biologie l'informatique, la musique et la psychologie. En général, les textes abordent des sujets très spécifiques reliés à un domaine. Par exemple, il pourrait y avoir 1000 textes parlant d'informatique et 100 qui abordent, à leur manière, la notion de mémoire. Parmi ces 100 passages, 5 pourraient aborder la mémoire dans un processeur spécifique.\n",
    "\n",
    "En ce qui concerne les questions, elles sont basées sur les sujets de certains textes précis et on peut y répondre à l'aide d'au moins un des textes. Dans certains cas, plusieurs textes sont nécessaires pour répondre à la question. Par exemple, plusieurs textes pourraient aborder le processeur Intel i7-13700k, mais la question pourrait nécessiter l'information de tous ces textes pour trouver la réponse.\n",
    "Les questions ont été créées pour faire en sorte que les réponses soient assez courtes. Il peut s'agir d'un simple nombre ou de quelques mots (< 30 mots).\n",
    "\n",
    "\n",
    "Vous trouverez ~ 13 000 passages dans le corpus pour ~ 1 700 paires de questions / réponses dans le jeu d'entraînement et ~ 500 dans le jeu de validation. Vous devez prédire 500 réponses aux questions du jeu de test.\n",
    "\n",
    "### Exemple\n",
    "\n",
    "Par exemple, pour la question\n",
    "\n",
    "> What type of bonds are used to form branches in glycogen?\n",
    "\n",
    "Avec l'approche RAG, plutôt que de générer la réponse directement, on va d'abord chercher dans un corpus de passages. Dans cet exemple, un des passages pertinents est :\n",
    "\n",
    "> **Glycogen Structure and Function** : Glycogen is a molecular polymer of glucose used for energy storage. It is composed of linear chains of glucose molecules linked by α-1,4-glycosidic bonds, with branches formed off the chain via α-1,6-glycosidic bonds. The branches provide additional \"\"free ends\"\" for linear chains, allowing for faster glucose release.\n",
    "\n",
    "Puis on génère une réponse conditionnée par les passages pertinents :\n",
    "\n",
    "> α-1,6-glycosidic bonds\n",
    "\n",
    "### Motivation\n",
    "\n",
    "Le RAG est une approche très populaire en ce moment. Elle permet notamment d'avoir des sources qui supportent les réponses générées, ce qui peut être utile pour la vérification de faits ou pour contrôler les hallucinations. De plus, elle permet d'intégrer des connaissances externes et récentes dans les modèles de génération sans avoir à les ré-entraîner.\n",
    "\n",
    "### Objectif du projet  \n",
    "\n",
    "Dans ce projet, nous allons implémenter plusieurs systèmes de question-réponse. Tout d'abord, nous testerons une approche de *prompting* qui ne s'appuie sur aucun passage pour aider le modèle de génération. Ensuite, nous mettrons en place un système figé utilisant un modèle de plongements statique pour retrouver les *k* passages les plus pertinents, qui seront ensuite fournis à un modèle de génération figé.  \n",
    "\n",
    "Enfin, nous développerons une nouvelle méthode en nous basant sur les dernières avancées de l'état de l'art afin d'optimiser les performances et d'atteindre des meilleurs résultats.\n",
    "\n",
    "### Jeux de données\n",
    "\n",
    "Nous avons 4 fichiers à notre disposition :\n",
    "- 'rag_texts.csv' : le corpus de passages extraits de Wikipédia.\n",
    "  - **id** : l'identifiant unique du passage.\n",
    "  - **text** : le texte du passage.\n",
    "- 'rag_questions_train.csv', 'rag_questions_val.csv' et 'rag_questions_test.csv' : les questions d'entraînement, de validation et de test.\n",
    "  - **id** : l'identifiant unique de la question.\n",
    "  - **question** : La question.\n",
    "  - **text_id** (sauf pour le fichier de test) : la liste des identifiants des passages pertinents du corpus 'rag_texts.csv' pour la question.\n",
    "  - **answer** (sauf pour le fichier de test) : la réponse à la question.\n",
    "\n",
    "### Sortie :  \n",
    "\n",
    "En sortie, notre modèle produira un fichier CSV contenant deux colonnes :  \n",
    "- **id** : l'identifiant de la question dans le jeu de données de test.  \n",
    "- **answer** : la réponse générée pour cette question.  \n",
    "\n",
    "Afin d'évaluer les performances de notre modèle sur l'ensemble de validation, nous utiliserons la métrique **BLEU**, qui permet de mesurer la similarité entre les réponses générées et les réponses de référence en comparant les n-grammes communs. Cette métrique est couramment utilisée pour évaluer la qualité des modèles de génération de texte, en particulier en traduction automatique et en question-réponse.\n",
    "\n",
    "### Note:\n",
    "\n",
    "- **Modèle génératif** : afin de mieux comparer les différentes approches, nous avons choisi d'utiliser exclusivement le modèle [microsoft/Phi-3-mini-128k-instruct](https://huggingface.co/microsoft/Phi-3-mini-128k-instruct), disponible sur Hugging Face. Cette contrainte garantit que les performances ne dépendent pas uniquement de la puissance du modèle de génération.  \n",
    "- **Modèles de plongements à utiliser** : [BAAI/bge-small-en-v1.5](https://huggingface.co/BAAI/bge-small-en-v1.5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TLhKFVblmzL"
   },
   "source": [
    "### 1.2. Description des données et métriques d’évaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oSbfbYpDXzzP",
    "outputId": "0bc94080-2090-43c9-d344-d45516ae85e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in ./.venv/lib/python3.10/site-packages (3.1.0)\n",
      "Requirement already satisfied: accelerate in ./.venv/lib/python3.10/site-packages (1.1.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.10/site-packages (from datasets) (2.1.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.venv/lib/python3.10/site-packages (from datasets) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.venv/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./.venv/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./.venv/lib/python3.10/site-packages (from datasets) (4.67.0)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./.venv/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in ./.venv/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.10/site-packages (from datasets) (3.11.7)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in ./.venv/lib/python3.10/site-packages (from datasets) (0.26.2)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.10/site-packages (from accelerate) (6.1.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.10/site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: torch>=1.10.0 in ./.venv/lib/python3.10/site-packages (from accelerate) (2.5.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.18.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YMXp0MTwYPoj",
    "outputId": "f07f2050-c7f9-404b-9636-e0589bdaa38d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-gpu in ./.venv/lib/python3.10/site-packages (1.7.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_Cb3zl_NWIcc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import des librairies\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import nltk\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t_NaUKGjWIcd",
    "outputId": "58d4eb67-ec3e-4027-fb39-a50ee1646eb5"
   },
   "outputs": [],
   "source": [
    "# Si vous stockez vos données sur Google Drive\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6rdAeRAAWIcd"
   },
   "outputs": [],
   "source": [
    "# root_path = '/content/drive/MyDrive/'\n",
    "# data_path = root_path + 'dataTp4/'\n",
    "\n",
    "data_path = 'data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DiPlzm88lmzM"
   },
   "source": [
    "## 2. Analyse exploratoire et modèle de génération simple \n",
    "\n",
    "Pour commencer ce projet et établir des modèles de base (*baselines*), nous allons utiliser un modèle de génération simple pour répondre aux questions. Nous travaillerons avec le modèle **'microsoft/Phi-3-mini-128k-instruct'**, disponible sur Hugging Face.  \n",
    "\n",
    "Dans cette première étape, nous générerons des réponses aux questions de l’ensemble de validation (*questions_val.csv*) sans utiliser de passages pour aider le modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jibrBtkRlmzM"
   },
   "source": [
    "### 2.1. Chargement des données "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEadi-LdWIce"
   },
   "source": [
    "#### 2.1.1 Taille des données \n",
    "\n",
    "Affichons la taille de tous les jeux de données et quelques questions de l'ensemble d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0gfo_V7jlmzM"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "train = pd.read_csv(data_path + 'questions_train.csv')\n",
    "val = pd.read_csv(data_path + 'questions_val.csv')\n",
    "test = pd.read_csv(data_path + 'questions_test.csv')\n",
    "text = pd.read_csv(data_path + 'texts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion des indices en liste de integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text_ids'] = train[\"text_ids\"].apply(lambda x: [int(i) for i in x.replace(\"[\", \"\").replace(\"]\", \"\").split(\" \") if i.isdigit()])\n",
    "val['text_ids'] = val[\"text_ids\"].apply(lambda x: [int(i) for i in x.replace(\"[\", \"\").replace(\"]\", \"\").split(\" \") if i.isdigit()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fuV3OJ7Gce5F",
    "outputId": "70ede383-cd13-4a50-91b5-eaf18a3fa349"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'entraînement: 1747\n",
      "Taille de l'ensemble de validation: 500\n",
      "Taille de l'ensemble de test: 500\n"
     ]
    }
   ],
   "source": [
    "print(f\"Taille de l'ensemble d'entraînement: {len(train)}\")\n",
    "print(f\"Taille de l'ensemble de validation: {len(val)}\")\n",
    "print(f\"Taille de l'ensemble de test: {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "vtRppnodc0P8",
    "outputId": "78173839-54ce-460b-adf9-e4754c534a4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    What type of insects are vectors for the Haemo...\n",
       "1    What is the basis of the security of the BBS a...\n",
       "2    What is the purpose of the catalase test in ba...\n",
       "3    What type of cells clear small particles in ve...\n",
       "4    What information is needed to decrypt a messag...\n",
       "Name: question, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"question\"].head()\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95a9VQUoWIce"
   },
   "source": [
    "#### 2.1.2 Analyse exploratoire \n",
    "\n",
    "a) Sur l'ensemble d'entraînement, affichons :\n",
    "- Le nombre moyen de mots dans une question\n",
    "- Le nombre moyen de mots dans une réponse\n",
    "- Le nombre moyen de passages nécessaires pour répondre à une question\n",
    "- Le nombre minimal de passages nécessaires pour répondre à une question\n",
    "- Le nombre maximal de passages nécessaires pour répondre à une question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TK1ziTwpWIcf",
    "outputId": "52781904-8579-4fe2-ee25-f12cec7a7626"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le nombre moyen de mots dans une question: 10.37263880938752\n",
      "Le nombre moyen de mots dans une réponse: 6.084144247281054\n",
      "Le nombre moyen de passages nécessaires pour répondre à une question: 2.839152833428735\n",
      "Le nombre minimal de passages nécessaires pour répondre à une question: 2\n",
      "Le nombre maximal de passages nécessaires pour répondre à une question: 4\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "mean_word_q = train[\"question\"].apply(lambda x: len(x.split())).mean()\n",
    "print(f\"Le nombre moyen de mots dans une question: {mean_word_q}\")\n",
    "\n",
    "mean_word_a = train[\"answer\"].apply(lambda x: len(x.split())).mean()\n",
    "print(f\"Le nombre moyen de mots dans une réponse: {mean_word_a}\")\n",
    "\n",
    "mean_passage = train['text_ids'].apply(lambda x: len(x)).mean()\n",
    "print(f\"Le nombre moyen de passages nécessaires pour répondre à une question: {mean_passage}\")\n",
    "\n",
    "min_passage = train['text_ids'].apply(lambda x: len(x)).min()\n",
    "print(f\"Le nombre minimal de passages nécessaires pour répondre à une question: {min_passage}\")\n",
    "\n",
    "max_passage = train['text_ids'].apply(lambda x: len(x)).max()\n",
    "print(f\"Le nombre maximal de passages nécessaires pour répondre à une question: {max_passage}\")\n",
    "\n",
    "# END TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1FymGxeWIcf"
   },
   "source": [
    "b) De plus, affichons des histogrammes décrivant la distribution du nombre de mots des questions, des réponses et des textes. Utilisez des bacs (bins) de 50. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "0IPXl6daWIcf",
    "outputId": "31aeda8a-f291-411a-d180-a9113bdfafd2"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "plt.hist(train[\"question\"].apply(lambda x: len(x.split())), bins=50)\n",
    "plt.title(\"Distribution du nombre de mots des questions\")\n",
    "plt.xlabel(\"Nombre de mots\")\n",
    "plt.ylabel(\"Fréquence\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "5e5iwY0Sd0L5",
    "outputId": "33c06c46-010e-4c5f-f762-e0852d94deae"
   },
   "outputs": [],
   "source": [
    "plt.hist(train[\"answer\"].apply(lambda x: len(x.split())), bins=50)\n",
    "plt.title(\"Distribution du nombre de mots des réponses\")\n",
    "plt.xlabel(\"Nombre de mots\")\n",
    "plt.ylabel(\"Fréquence\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "_dyBEk3Ld4Fq",
    "outputId": "21dd17c2-0818-4ab7-9f72-05e60c3b6b4d"
   },
   "outputs": [],
   "source": [
    "plt.hist(text[\"text\"].apply(lambda x: len(x.split())), bins=50)\n",
    "plt.title(\"Distribution du nombre de mots des passages \")\n",
    "plt.xlabel(\"Nombre de mots\")\n",
    "plt.ylabel(\"Fréquence\")\n",
    "plt.show()\n",
    "#END TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CGcqPv81WIcf"
   },
   "source": [
    "COMMENTAIRE:\n",
    "\n",
    "- Les questions sont en moyenne plus longues que les réponses\n",
    "\n",
    "- Les réponses sont très courtes\n",
    "\n",
    "- Les passages font en moyenne 40 mots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMgR_b3nlmzM"
   },
   "source": [
    "### 2.2. Chargement du modèle et génération des réponses \n",
    "\n",
    "Nous allons maintenant évaluer la performance d'un modèle de langue à répondre aux questions de l'ensemble de validation. Chargeons d'abord le modèle **'microsoft/Phi-3-mini-128k-instruct'** avec la librairie `transformers` de huggingface et générons les réponses du modèle à partir de la question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "scWSMo5KylpK"
   },
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "READER_MODEL_NAME = \"microsoft/Phi-3-mini-128k-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525,
     "referenced_widgets": [
      "b43f843d13514cd9a0172e39d9d3592b",
      "15b245c35bf242a2bd2529024cbe90bc",
      "058e46f1a67848bc84395329d9277d81",
      "b3cc9b9c64a24113afdb9cac97d25f2a",
      "4d30cfc3292d4f72b6b3c430aa28f97b",
      "ade4f0035e57486bb66ea68ed8b12d45",
      "e916b30ee67947648d62c19e4219b299",
      "0231aba660a24c65a17b81c630d20026",
      "6fb12bfc3b754744859c5e4957f0cde8",
      "32098b40dd55469fa4af3f05c2a38352",
      "14b1bc5448a248d6862d595e50f03222",
      "5bd0839a7bbd4689b884e83da7872560",
      "9e153cf6f50a422f8a1aca4edaa4fa0c",
      "817fc0fc03af413a93bf5fc4c73aaac2",
      "a7bb560d04cf48f3a7f1b2c7e9133a68",
      "3d552f2995d54689a23cf26b3d7b2c56",
      "c7b0180ab48249b3ac8ca98e12a33832",
      "be79f6b321f64f14bda4c389f7de00e0",
      "adecbb7a15db476e89ce91326815c67e",
      "f748dd63b25b480284a15931521a20d1",
      "bb2597d7172a4d8b87da4081d4434bf0",
      "f87d77c729814e2dbabf6fd3b4a45fdb",
      "bc98025f3f7f4ae2a5d5ea6bdf2731be",
      "c54c408e578545d0b8927adc3711eb06",
      "e7c44e300a4c4f6981e12c579a5da52f",
      "359ed76056204ec6bdd39735864ede56",
      "6601b467bcc146c58f5113f60456cacd",
      "23af9a14740d4c63ae613788034b6306",
      "3f4b1f7416b143fab4aa622255049b25",
      "474d7f16e4384284850da8aa31180fc7",
      "bddb24c828494cc59fd1cb431907e2da",
      "6c9a62605ea849199b5496f1ce5b40f2",
      "8be1e6ccb2c44174828c61b465f09f4f",
      "04b75b0c26804388a350d07a30ccf372",
      "af486d048dbd4201b7fb49e5b7d8b064",
      "aaed6739df41459c83da11f83a4d7831",
      "619558982dc743c6873e0aa35b9cab95",
      "673d4896dedf4f7f8e8cdf99496106cb",
      "f8b65786ec954c84a4e5570f9267469b",
      "a0338bc56d764ac4a545ca6cc359d166",
      "d16a16915682493aaa6d9808c51b854a",
      "91e5cd59d91c424a9126d2cb547ab660",
      "a0d8a47f8b8e41df8a1dfe0d58fd4fb5",
      "8fccabe982914cae816b4646e9eb7dd1",
      "989f479eeb7b41a4b6895b3b4efdf835",
      "7fe4c8115e5b4493aef87524615ea85a",
      "6985937a68bb4d79957b8211b1e5388a",
      "e137799f05b24817a2bf65c2a43eb992",
      "566f28b2eeb84d08b979c732212cc179",
      "11eff816d23d4f72aa631ff7217a3693",
      "df7dfaf2f1bb4f0191cb357dd8be4c53",
      "3b99f8dc315b4eed814f820c37c4ec70",
      "0d5856151ab0427e9b1cbb9fa7c75898",
      "f60deb43aa074d009f2fb0ee36a46852",
      "d53361106b504cb7a0dbe33d0e9f9cd3",
      "ad1d395ab02b488b8fa42445d4311f86",
      "d4d282b50e9d490f95146540f6a9019f",
      "29a90894f6434935872673f1d2c5ad6f",
      "82a7487a0007416e87ac67234acdd3eb",
      "3976b388644c43a4b0cabb927ca02e63",
      "f1e77d1e6f564f22af7855b4c5403382",
      "1caf97c36e214739bf381f127c156b47",
      "eab47f2e8b914ef5a2f94299cde9a9c5",
      "d33cf6b76aaf45fc8b700f8840a7c88b",
      "b637052dd85d46da91ab0903367fc7c1",
      "d5297ca62d4649298f803c7d9860e6c9",
      "c2afad340d0941439b6e795e49054a3f",
      "a4a9a434e6184a84a15d695f59304c3a",
      "97a5e56e0ccb4765ade980dbb81a53e4",
      "0121585c05d245b1a8a6d00a80810020",
      "1ae7f9a1f977494e89b860efafc6d1c8",
      "6339813d2aed49aab357b99859d334d2",
      "82fd691d12fc47ec8cdc0b43e69851ca",
      "910760b916c746c99ff2d9bd56afaa92",
      "66f26783d40948d192429c77bfdcf2ec",
      "75845ea818864a05b6b81d892c918fbb",
      "6a0ff00b9fa74d39be07b5171b67ee6d",
      "e0629709cb8d464588012a1faa11157f",
      "db434b2cacb943779dd5f273f5ac00b8",
      "244aa48ea2c14568877a1d011109a0b4",
      "50241bae59fb4d62aaa601ed65d197da",
      "777b16dc4a2b4700bf00a0c326f4088a",
      "0b281386c3d24d098198942fce1aee9e",
      "c86be5835b2d4e22b36c67c4f6bdbc18",
      "cff71520ea0f47cab63a9b4547ead389",
      "0772addcbe7d4940a78d57045df41680",
      "9f96be95ad31461589a26068d6f03a77",
      "d94c9ec3e4d146c08cf7bcb130547e1c",
      "f37c13a1e38a4ba8a9ad70eddcc4ee7c",
      "0262d754496d4abe99bedde39a46feff",
      "60585708ae544f3296bafa73f1dc3a80",
      "fef3cf511e7e465f8f083641325e6ffb",
      "69b3680cbd724f57b8db313a2b93e514",
      "4221debc451b4befb771ab89469005e4",
      "51da695ae4da468799789fa00642f29d",
      "83eda8c23bec4b258314df9ce6c7fef3",
      "4d031cce2c7e44eb926164c978e2976c",
      "cf82fa5bc83f4e1889f60bdb25457942",
      "cfc9a77f379e4f32b8e58fa3ffa664ca",
      "61a0576380144b91b149f5c521d158d1",
      "ca231ce9920b4c4785e74f7be9c5350c",
      "2adb0e097d1345c59cedf9b59340b2ba",
      "27f81e096735470e9134d2291639b35d",
      "aa4a1be513e64426924ae75d41bd3a2a",
      "dd47caa8a2304b4a9708f6d3fc2bbdca",
      "d594a05b05d64d619f70785f1e0c5474",
      "2dad103b367649e392c8cdecab4bb1f0",
      "a371bff9659549809531211ade04e6b9",
      "3c137349e69647938564aa94e080c3fa",
      "6b856bebdd7941eebd258243c6e7e0f0",
      "135b6353dd75494e9e805092efa309dd",
      "d7afb8f700124dedade03d5af1ccbcbc",
      "364c6c33f112432abf6622c2ead487bb",
      "b8411a6c8d244047917292330d9e6fd6",
      "d0349b79945b49b082c08e831382f033",
      "8219e9f52b7446fbbcdec49efa3d4d30",
      "411d27a54ed74fbb9190c6a0286caf2f",
      "6f37495ff86046f8961220149debbb98",
      "adfcec3f3afb4ed197d67c38aab09429",
      "26060baa46414745922edd51663ce514",
      "8b4b8b4d34d248c39fbdf08226986624",
      "08fab801a16347fbb6b3760e3a1f213c",
      "69d82e3ef95547d0bc42fb132ee37fea",
      "36a2190c165340abbd7547b4cac177bd",
      "7f278bceefb84521aa20ed388bbc0ea4",
      "dac10bcd070545ac945109b9e586832e",
      "07a82338400b49de87e5d3ceed2bac03",
      "1fd82241c79147b89249641b758486c4",
      "5298db0fb62b45deaca2ebc8d42a43d4",
      "993fe4518a084125af1fdb0e1b5f5af9",
      "791b25855f584a74a97a409e533b41b4",
      "8903451f294140e584100c601dc5167d"
     ]
    },
    "id": "_qEIyfc8dg-k",
    "outputId": "941ea588-7774-4f53-a36b-f50af30b43e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.28s/it]\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "model_reader = AutoModelForCausalLM.from_pretrained(\n",
    "    READER_MODEL_NAME,\n",
    ")\n",
    "tokenizer_reader = AutoTokenizer.from_pretrained(READER_MODEL_NAME)\n",
    "\n",
    "READER_LLM = pipeline(\n",
    "    model=model_reader,\n",
    "    tokenizer=tokenizer_reader,\n",
    "    task=\"text-generation\",\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=False,\n",
    "    device= 0 if DEVICE == \"cuda\" else -1,\n",
    "    max_new_tokens=32,\n",
    ")\n",
    "# END TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pX9wHXuolmzN"
   },
   "source": [
    "### 2.3. Évaluation des réponses \n",
    "\n",
    "Nous allons créer la fonction `evaluate_bleu` et utiliser la métrique BLEU pour évaluer les réponses générées par rapport aux réponses attendues sur le jeu de validation. Nous évaluerons notre modèle avec les métriques **BLEU-1** et **BLEU-2** :  \n",
    "\n",
    "- **BLEU-1** prend en compte uniquement les unigrammes pour évaluer la qualité des réponses.  \n",
    "- **BLEU-2** intègre également les bigrammes pour une évaluation plus fine.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "gcix6hdJlmzN"
   },
   "outputs": [],
   "source": [
    "def evaluate_bleu(df_true: pd.DataFrame, df_pred: pd.DataFrame, bleu_type: int):\n",
    "    \"\"\"\n",
    "    Évalue les réponses générées en utilisant la métrique BLEU.\n",
    "\n",
    "    Paramètres:\n",
    "    df_true (pd.DataFrame): DataFrame contenant les vraies réponses avec des colonnes 'id' et 'answer'.\n",
    "    df_pred (pd.DataFrame): DataFrame contenant les réponses prédites avec des colonnes 'id' et 'answer'.\n",
    "    bleu_type (int): Nombre (soit 1 ou 2) correspondant aux n-grammes considérés pour la métrique (bleu_type = 1 : BLEU-1, bleu_type = 2 : BLEU-2)\n",
    "\n",
    "    Retourne:\n",
    "    float: Score BLEU moyen sur toutes les entrées.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    scores = []\n",
    "    for i in range(len(df_true)):\n",
    "        true_answer = df_true.iloc[i]['answer']\n",
    "        pred_answer = df_pred.iloc[i]['answer']\n",
    "        if bleu_type == 1:\n",
    "            scores.append(sentence_bleu([true_answer.split()], pred_answer.split(),weights=(1, 0, 0, 0)))\n",
    "        elif bleu_type == 2:\n",
    "            scores.append(sentence_bleu([true_answer.split()], pred_answer.split(),weights=(0, 1, 0, 0)))\n",
    "        else:\n",
    "            raise ValueError(\"bleu_type 1 or 2\")\n",
    "    return np.mean(scores)\n",
    "\n",
    "    # END TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "fMQP4HytlmzN"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "questions = val[\"question\"].tolist()\n",
    "\n",
    "predictions = READER_LLM(questions, batch_size=1)\n",
    "\n",
    "pred = [output[0][\"generated_text\"] for output in predictions]\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "df_pred = pd.DataFrame({\"id\": val[\"id\"], \"answer\": pred})\n",
    "df_true = val[[\"id\", \"answer\"]]\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kBsLpF3Tu7Uc",
    "outputId": "5ba4d145-8de3-413a-dbaa-30e31f1e8254"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "bleu_1 = evaluate_bleu(df_true, df_pred, 1)\n",
    "bleu_2 = evaluate_bleu(df_true, df_pred, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vRcM2kiT1LK8",
    "outputId": "5c98a953-23f9-4398-89ae-3a1b7dabae63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.06517458063112228\n",
      "BLEU-2: 0.012476048968439521\n"
     ]
    }
   ],
   "source": [
    "print(f\"BLEU-1: {bleu_1}\")\n",
    "print(f\"BLEU-2: {bleu_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuPpGiSZmAbl"
   },
   "source": [
    "BLEU-1: 0.06517458063112228\n",
    "BLEU-2: 0.012476048968439521"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9Her6pglmzN"
   },
   "source": [
    "### 2.4. Commentaire \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHMF79ccxcfr"
   },
   "source": [
    "Performance obtenue:\n",
    "\n",
    "- BLEU-1: 0.06662334044572885\n",
    "\n",
    "- BLEU-2: 0.015467704378992813\n",
    "\n",
    "-> Les perfomances sont très faibles. Le modèle n'a pas été entrainé sur ce sujet, ne peux donc répondre sans contexte.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SKv1Mb7DlmzN"
   },
   "source": [
    "## 3. Approche RAG figé \n",
    ".lightning_studio\n",
    "Dans cette partie, nous allons implémenter une approche simple de **RAG figé**. Ce modèle est qualifié de figé car aucun ré-entraînement n’est effectué. Nous mettrons en place deux variantes : avec ou sans l'utilisation d'un algorithme d'indexation.  \n",
    "\n",
    "Dans cette approche, nous commencerons par retrouver les passages pertinents pour chaque question à l'aide d'un modèle de plongements basé sur Transformers, puis nous générerons une réponse conditionnée par ces passages.  \n",
    "\n",
    "Pour cela, nous utiliserons :  \n",
    "- **[BAAI/bge-small-en-v1.5](https://huggingface.co/BAAI/bge-small-en-v1.5)** comme modèle de plongements (*embedding model*) afin d'obtenir les vecteurs des questions et des passages.  \n",
    "- **[microsoft/Phi-3-mini-128k-instruct](https://huggingface.co/microsoft/Phi-3-mini-128k-instruct)** comme modèle de génération (*generative model*) pour produire les réponses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVDX1sDyd1AR"
   },
   "source": [
    "### 3.1 RAG figé sans indexation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "MT9bTa0LiFxz"
   },
   "outputs": [],
   "source": [
    "EMBED_MODEL_NAME = \"BAAI/bge-small-en-v1.5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bGXPWfqXlmzN"
   },
   "source": [
    "#### 3.1.1 Passages pertinents \n",
    "\n",
    "Pour retrouver les passages pertinents, nous avons encodé les questions et les passages avec le modèle de plongements. Puis, nous avons calculé la similarité cosinus entre les questions et les passages pour retrouver les $k$ passages les plus pertinents pour chaque question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209,
     "referenced_widgets": [
      "494d02243fcf4717a8ca4ab9a1d86134",
      "7b0b017442ed44a2afffa945fdc3760f",
      "ce7eb1bc7bb84319afa8066ac5d929c2",
      "f0901fedbe5548f395713b267453156a",
      "22fc3386dd98456291cbe743c6e9e4b3",
      "f58d09ee472946b58c3a78efcd252286",
      "8d33212e73164f06a52cd0cdb9d2b510",
      "10b3a512cdd547099e8edabfed84ccc1",
      "af9dee883fc44b7289ba4869e641be9f",
      "663923a0b2574caa81af0c326c026e7a",
      "c3a219ad044942e19423fa1d306012fc",
      "0fa84229ff6e4ea8b6221ca9a44b0499",
      "79d7239639804379ad3819aab330e1f9",
      "09619988ac094e4c94039d2279e0dfbc",
      "abc39658b8a6406bb3479f66e4591332",
      "0393be4ac85748c0a566f21810b11797",
      "30088f44ebb744618ec6a73da82ebded",
      "9e42bead1abb4c738f371445e47aaec2",
      "6e01e9110ece4fda82d6398754dcbbb6",
      "14c0a01ee8964f7984cf434fefacc506",
      "ba9e4181a77549feae1aa5d9f4317f91",
      "265e8d73fb8a44dba45ae903ddb0e434",
      "8f45ffa19c9542c6a7f3ae240274f0bd",
      "b2cd5263eea54ac9b1e070a088fa314c",
      "2cb94efd0a214728b10ae033423563cc",
      "212dfbabcc1a43a5aff492d1e2e0a1a1",
      "37ad66b737f144e59c04ad5cafe914ee",
      "520d6abdce0d4f77a71101af317bb1e3",
      "d228806adc344076911f2a24e0261016",
      "07c97b63f17c4079ad617a0106411d77",
      "7e61b106ba36440f8f156255b7d7e8d7",
      "0e2ab26263e24ddeb71e03e23f653163",
      "e37915040019425c869d4fcdb0f806b1",
      "c4a3dae4ccac4c80830b90e40aeff0d9",
      "552114a8b889485697e484daf03a48e2",
      "6097d8dd41194e27b4208bcc163ec230",
      "8b24846dc0b940eea57733078a627db6",
      "75ebc75a747d4a93b523d82d9ee7ed70",
      "56d94a63406c423a974726de4a6e451d",
      "50f6dc7b3bb84eedb5e9977209df0a4b",
      "b6d8389172e744cea274082c7d88221e",
      "1fcf72f149a24287a76047d117704bed",
      "12f4c1321b814bbea00412916e62eaa2",
      "506e4a81a6bb402fbc5076922e554c72",
      "5e85e59b59f6445f9f6914abcfc696cf",
      "8d52a69c82c948ee8bf96d3e064ceb63",
      "60258885b3734ac6b8db9153e34f0739",
      "4bc975111b2449ce80bee91afcdeab49",
      "827325ceb39b4483a0171ff877907cec",
      "8eb5b8edd1e14ee09f8d501fa3d04c14",
      "0c6f5acb28444ac2804e6531231e2f39",
      "7aa50c755dd0432a8e7a4a9ef947883f",
      "b010da7e40e9470cae6b964c25573b98",
      "38d560a38fac4bc7a8ffe30f80b11f69",
      "a48e9f06b2434c3cad78a40cc1623966",
      "134fcf9e6d1b4f7095d83a922353e701",
      "ee3836da25bf471fb7a3b8fb0f342937",
      "d10b341ed6c34e25a6110f45c2b5f2dc",
      "ee8347d4af2b473289aedfd5d47b0069",
      "4e57515c1d0c4e56b9937fb0749ff03d",
      "e2e6d0a35eba4f3d90a49c14def54ae4",
      "3bd94d1a53bc4e968bdbc48f8234e5cf",
      "21cf18c5d7004f969ecc12df3379991a",
      "e212d76cc0e44b0691b8584c2d7ea10f",
      "600fc4f518ba4078bcf0e3cd9b2b2495",
      "b60b1f0164204e73b28ae8a2c1595d9e"
     ]
    },
    "id": "uCj_YUkUWIch",
    "outputId": "1dc8a95f-99b5-464c-e598-0b57dc9380eb"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "tokenizer = AutoTokenizer.from_pretrained(EMBED_MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(EMBED_MODEL_NAME)\n",
    "# END TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "3qdWbf1AlmzN"
   },
   "outputs": [],
   "source": [
    "def encode_sequences(sequences: list, tokenizer, model, device = DEVICE, batch_size = BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Encode les textes en utilisant le modèle passé en paramètre pour générer les plongements des textes\n",
    "\n",
    "    Paramètres:\n",
    "    sequences    : Liste de séquence à transformer en plongements\n",
    "    tokenizer   : Segmenteur du modèle de plongements\n",
    "    model       : Modèle de plongements\n",
    "    device      : Machine sur laquelle les opérations doivent être effectuées\n",
    "    batch_size  : Taille des lots lors de la génération des traitements\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(sequences), batch_size):\n",
    "\n",
    "            batch_sequences = sequences[i:i + batch_size]\n",
    "\n",
    "            # Tokenizer\n",
    "            tokens_sentences = tokenizer(batch_sequences, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "            #Embedding\n",
    "            embed_sentences = model(**tokens_sentences)\n",
    "\n",
    "            embeddings.extend(embed_sentences[0][:,0])\n",
    "\n",
    "    embeddings = torch.stack(embeddings)\n",
    "    return embeddings\n",
    "    # END TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "JbpTRPuTlmzO"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "encoded_passages = encode_sequences(text[\"text\"].to_list(), tokenizer, model)\n",
    "# END TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ArSjDkwWIci"
   },
   "source": [
    "#### 3.1.2 Évaluation des passages retrouvés avec Recall@k et precision@k \n",
    "\n",
    "Maintenant que les passages ont tous été encodés, on peut évaluer si les passages retrouvés sont pertinents. En prenant les $k$ premiers passages, on peut évaluer si on retrouve les bons passages associés aux questions. C'est un des avantages du système RAG : on peut évaluer de façon indépendante la qualité du système qui retrouve les passages pertinents et de celui qui génère les réponses. Cela permet notamment d'évaluer quels sont les points forts et points faibles du système.\n",
    "\n",
    "Pour cela, nous allons utiliser les métriques **Precision@k** et **Recall@k** définies dans les équations suivantes. \n",
    "\n",
    "$$\\text{Precision@k} = \\frac{\\text{Nombre d'éléments pertinents dans les k premiers}}{k}$$\n",
    "\n",
    "$$\\text{Recall@k} (Rappel@k) = \\frac{\\text{Nombre d'éléments pertinents dans les k premiers}}{\\text{Nombre total d'éléments pertinents}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Fu-EbJosWIci"
   },
   "outputs": [],
   "source": [
    "def compute_recall_at_k(ground_truth, predictions):\n",
    "    \"\"\"\n",
    "    Calcule la métrique du \"Recall@k\". On assume que predictions contiennent le bon nombre de passages (=k)\n",
    "\n",
    "    Paramètres:\n",
    "    ground_truth : Liste contenant tous les vrais passages associés aux questions (ex : [[1, 2, 3], [4, 5, 6]] si les passages de la question 1 sont [1, 2, 3] et\n",
    "    les passages de la question 2 sont [4, 5, 6])\n",
    "    predictions : Liste contenant tous les passages retrouvés pour chacune des questions formattée de la même manière que `ground_truth`\n",
    "\n",
    "    Retourne:\n",
    "    Recall moyen\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    recalls = []\n",
    "    for i in range(len(ground_truth)):\n",
    "        #return the size of the intersection\n",
    "        nbk = len(set(ground_truth[i]) & set(predictions[i]))\n",
    "        recalls.append( nbk / len(ground_truth[i]))\n",
    "    return np.mean(recalls)\n",
    "\n",
    "\n",
    "    # END TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "JaaTqwyGWIci"
   },
   "outputs": [],
   "source": [
    "def compute_precision_at_k(ground_truth, predictions):\n",
    "    \"\"\"\n",
    "    Calcule la métrique du \"Precision@k\". On assume que predictions contiennent le bon nombre de passages (=k)\n",
    "\n",
    "    Paramètres:\n",
    "    ground_truth : Liste contenant tous les vrais passages associés aux questions (ex : [[1, 2, 3], [4, 5, 6]] si les passages de la question 1 sont [1, 2, 3] et\n",
    "    les passages de la question 2 sont [4, 5, 6])\n",
    "    predictions : Liste contenant tous les passages retrouvés pour chacune des questions formattée de la même manière que `ground_truth`\n",
    "\n",
    "    Retourne:\n",
    "    Précision moyenne\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO\n",
    "    precisions = []\n",
    "    for i in range(len(ground_truth)):\n",
    "        nbk = len(set(ground_truth[i]) & set(predictions[i]))\n",
    "        precisions.append(nbk / len(predictions[i]))\n",
    "    return np.mean(precisions)\n",
    "\n",
    "    # END TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKzC3jp6WIci"
   },
   "source": [
    "#### 3.1.3 Résultat d'évaluation \n",
    "On implemente la fonction _'retrieve_passages'_ qui retourne les indices des $k$ passages les plus similaires pour une question. On utilise la similarité cosinus pour comparer les passages et les questions. Nous allons ensuite evaluer notre modèle de récupération en comparant notre sortie au passages pertinent du dataset de validation avec les métriques Precision@k et Recall@k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "32-jSgRJvlfj"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "IOrjAdbGWIcj"
   },
   "outputs": [],
   "source": [
    "def retrieve_passages(questions: list, passage_embed: torch.Tensor, k: int, embedding_model_tokenizer, embedding_model):\n",
    "    \"\"\"\n",
    "    Retourne les k passages les plus pertinents pour chaque question passée en paramètre\n",
    "\n",
    "    Paramètres:\n",
    "    questions       : Les questions pour lesquelles on cherche les passages les plus pertinents\n",
    "    passage_embed   : Tenseur contenant les plongements de chaque passage (n, dim)\n",
    "    k               : le nombre de passages à retourner\n",
    "    tokenizer       : Segmenteur du modèle de plongements\n",
    "    model           : Modèle de plongements\n",
    "\n",
    "    Retourne:\n",
    "    Les indices des k passages les plus pertinents pour la question\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "\n",
    "\n",
    "    all_top_k_indices = []\n",
    "    batch_size = 16\n",
    "    # compute cos sim with batch to not run out of memory\n",
    "    for i in range(0, len(questions), batch_size):\n",
    "        batch_questions = questions[i:i + batch_size]\n",
    "\n",
    "        encoded_questions = encode_sequences(batch_questions, embedding_model_tokenizer, embedding_model)\n",
    "\n",
    "        similarity_scores = F.cosine_similarity(\n",
    "            encoded_questions.unsqueeze(1), passage_embed.unsqueeze(0), dim=2\n",
    "        )\n",
    "\n",
    "        # Best k passages\n",
    "        top_k_indices = similarity_scores.topk(k, dim=1).indices\n",
    "        all_top_k_indices.append(top_k_indices)\n",
    "\n",
    "        # delete unused elements\n",
    "        del encoded_questions, similarity_scores, top_k_indices\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    all_top_k_indices = torch.cat(all_top_k_indices, dim=0)\n",
    "    return all_top_k_indices\n",
    "\n",
    "    # END TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "XiHNqqZHWIck"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "best_1_passages = retrieve_passages(train[\"question\"].to_list(), encoded_passages, 1, tokenizer, model)\n",
    "best_2_passages = retrieve_passages(train[\"question\"].to_list(), encoded_passages, 2, tokenizer, model)\n",
    "best_3_passages = retrieve_passages(train[\"question\"].to_list(), encoded_passages, 3, tokenizer, model)\n",
    "best_4_passages = retrieve_passages(train[\"question\"].to_list(), encoded_passages, 4, tokenizer, model)\n",
    "# END TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dJyouG7WIck"
   },
   "source": [
    "#### 3.1.4 Graphique (3 points)\n",
    "Affichons maintenant un graphique de nos résultats de la question précédente, en représentant sur l'axe des **x** la valeur de *k* et sur l'axe des **y** la précision et le rappel.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "w5nzxO1mWIck"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "precisions_1 = compute_precision_at_k(train['text_ids'], best_1_passages.tolist())\n",
    "recall_1 = compute_recall_at_k(train['text_ids'], best_1_passages.tolist())\n",
    "\n",
    "precisions_2 = compute_precision_at_k(train['text_ids'], best_2_passages.tolist())\n",
    "recall_2 = compute_recall_at_k(train['text_ids'], best_2_passages.tolist())\n",
    "\n",
    "precisions_3 = compute_precision_at_k(train['text_ids'], best_3_passages.tolist())\n",
    "recall_3 = compute_recall_at_k(train['text_ids'], best_3_passages.tolist())\n",
    "\n",
    "precisions_4 = compute_precision_at_k(train['text_ids'], best_4_passages.tolist())\n",
    "recall_4 = compute_recall_at_k(train['text_ids'], best_4_passages.tolist())\n",
    "# END TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "3VdK_7Dm2uGl"
   },
   "outputs": [],
   "source": [
    "def plot_retrieval(measures,k,title,axes) :\n",
    "\n",
    "  fig = plt.figure(figsize=(10, 5))\n",
    "  ax1 = fig.add_subplot(121)\n",
    "\n",
    "  # Tracé de la courbe avec des marqueurs et une couleur\n",
    "  ax1.plot(axes, measures,\n",
    "          marker='o', color='b', linestyle='-', linewidth=2, markersize=6, label=title)\n",
    "\n",
    "  # Ajout des labels et du titre\n",
    "  ax1.set_xlabel('k', fontsize=12, fontweight='bold')\n",
    "  ax1.set_ylabel(title, fontsize=12, fontweight='bold')\n",
    "  ax1.set_title(f'Courbe de {title} en fonction de k', fontsize=14, fontweight='bold')\n",
    "\n",
    "  ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "  ax1.set_xlim(1, len(axes))\n",
    "  ax1.set_ylim(0, 1)\n",
    "\n",
    "  # Affichage\n",
    "  plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 997
    },
    "id": "HbUe6KsJ34S9",
    "outputId": "b0e67daf-5354-47c6-e9be-6ad7688d437d"
   },
   "outputs": [],
   "source": [
    "precisions = [precisions_1, precisions_2, precisions_3, precisions_4]\n",
    "recalls = [recall_1, recall_2, recall_3, recall_4]\n",
    "plot_retrieval(precisions, \"k\", \"Precision\",[1, 2, 3, 4])\n",
    "plot_retrieval(recalls, \"k\", \"Recall\",[1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Te7KVZiE_fxD"
   },
   "source": [
    "-> On cherche un équilibre entre la précision et le rappel. Une haute précision implique choisir un k plus petit mais un rapel faible. On souhaite récupérer un nombre suffisant de documents pertinents sans ajouter du bruit. Au regard des graphiques on choisit ainsi k=3. De cette manière au fait correspondre notre k au nombre moyen de documents par question étant de envion de 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8K_W3diFg0ae"
   },
   "source": [
    "### 3.2 RAG figé avec FAISS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlYM7rVOJumv"
   },
   "source": [
    "Maintenant, nous allons utiliser **FAISS** pour l'indexation des plongements des passages.  \n",
    "\n",
    "[FAISS (*Facebook AI Similarity Search*)](https://ai.meta.com/tools/faiss/) est une bibliothèque open-source développée par Meta pour la recherche de similarité rapide sur des vecteurs denses, comme des *embeddings* de textes ou d'images. Elle est optimisée pour traiter de grands volumes de données en haute dimension et peut tirer parti des GPU pour accélérer les calculs.  \n",
    "\n",
    "FAISS est largement utilisée dans les systèmes de recommandation et la recherche d'information à grande échelle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bcauZveIK4P1"
   },
   "source": [
    "#### 3.2.1 Initialisez l'indexation FAISS avec les plongements des passages \n",
    "\n",
    "Nous allons utiliser les plongements des passages générés à la question **3.1.1** et les indexer avec **FAISS**. Nous vérifierons que le nombre de plongements dans l'objet FAISS correspond bien au nombre de passages.  \n",
    "\n",
    "Il est important de s'assurer que l'indexation est basée sur la **similarité cosinus** pour garantir des résultats pertinents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "kZivFPUkWIcl"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# déplacement sur cpu pour normaliser\n",
    "encoded_passages = encoded_passages.cpu().numpy()\n",
    "#Normalisation\n",
    "encoded_passages = encoded_passages / np.linalg.norm(encoded_passages, axis=1, keepdims=True)\n",
    "\n",
    "index = faiss.IndexFlatIP(encoded_passages.shape[1]) # Inner Product pour la similarité cosinus\n",
    "index.add(encoded_passages)\n",
    "# END TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5uomxKyuto2W",
    "outputId": "14d8fa36-272d-4297-a21e-f6776a5ff301"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de vecteurs indexés dans FAISS : 13314\n"
     ]
    }
   ],
   "source": [
    "assert index.ntotal == encoded_passages.shape[0]\n",
    "\n",
    "print(f\"Nombre de vecteurs indexés dans FAISS : {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EU-dtdjmLGF5"
   },
   "source": [
    "#### 3.2.2 Récupération des passages avec FAISS \n",
    "\n",
    "Implémentons la fonction `_retrieve_passages_faiss_`, qui renvoie les indices des *k* passages les plus similaires à une question en utilisant une indexation avec **FAISS**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "N4nPlN8hN41H"
   },
   "outputs": [],
   "source": [
    "def retrieve_passages_faiss(questions: list, vector_index: faiss.IndexFlatL2, k: int, embedding_model_tokenizer, embedding_model):\n",
    "    \"\"\"\n",
    "    Retourne les k passages les plus pertinents pour chaque question passée en paramètre\n",
    "\n",
    "    Paramètres:\n",
    "    questions       : Les questions pour lesquelles on cherche les passages les plus pertinents\n",
    "    vector_index    : L'objet d'indexation FAISS\n",
    "    k               : le nombre de passages à retourner\n",
    "    tokenizer       : Segmenteur du modèle de plongements\n",
    "    model           : Modèle de plongements\n",
    "\n",
    "    Retourne:\n",
    "    Les indices des k passages les plus pertinents pour la question\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    #plongements des questions\n",
    "    encoded_questions = encode_sequences(questions, embedding_model_tokenizer, embedding_model)\n",
    "    encoded_questions = encoded_questions.cpu().numpy()\n",
    "    encoded_questions = encoded_questions / np.linalg.norm(encoded_questions, axis=1, keepdims=True)\n",
    "\n",
    "    #Retrieval\n",
    "    dists, idx = vector_index.search(encoded_questions, k)\n",
    "\n",
    "    return idx\n",
    "    # END TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkvrBasfWIcl"
   },
   "source": [
    "#### 3.2.3 Exécution de FAISS \n",
    "\n",
    "Nous allons maintenant exécuter la fonction `_retrieve_passages_faiss_` afin de récupérer les passages les plus pertinents pour les questions du jeu de validation, en utilisant notre valeur optimale de *k*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "A7mJ_jbHOBBq"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "best_1_passages_faiss = retrieve_passages_faiss(val[\"question\"].to_list(), index, 1, tokenizer, model)\n",
    "best_2_passages_faiss = retrieve_passages_faiss(val[\"question\"].to_list(), index, 2, tokenizer, model)\n",
    "best_3_passages_faiss = retrieve_passages_faiss(val[\"question\"].to_list(), index, 3, tokenizer, model)\n",
    "best_4_passages_faiss = retrieve_passages_faiss(val[\"question\"].to_list(), index, 4, tokenizer, model)\n",
    "best_5_passages_faiss = retrieve_passages_faiss(val[\"question\"].to_list(), index, 5, tokenizer, model)\n",
    "# END TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gmHFzjkUMXsR"
   },
   "source": [
    "#### 3.2.4 Calculons les métriques Precision@K et Rappel@K pour les passages retrouvés avec FAISS avec notre k optimal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "XlL3pfYsObrX"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "precisions_3 = compute_precision_at_k(val['text_ids'].to_list(), best_3_passages_faiss.tolist())\n",
    "recall_3 = compute_recall_at_k(val['text_ids'].to_list(), best_3_passages_faiss.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JcrvdKzkx_Wz",
    "outputId": "cf59a3e2-f9d8-4f92-8e4f-d653cb295522"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@3: 0.5593333333333333\n",
      "Recall@3: 0.6031666666666666\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision@3: {precisions_3}\")\n",
    "print(f\"Recall@3: {recall_3}\")\n",
    "# END TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8rBSiVPn_fxI"
   },
   "source": [
    "-> Nous obtenons ainsi une précision de 0.55 et un rapel de 0.60."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UhHnwSJ_fxI"
   },
   "source": [
    "Observons pour les autres k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "FDkoLuQ4_fxI"
   },
   "outputs": [],
   "source": [
    "precisions_1 = compute_precision_at_k(val['text_ids'], best_1_passages_faiss.tolist())\n",
    "recall_1 = compute_recall_at_k(val['text_ids'], best_1_passages_faiss.tolist())\n",
    "\n",
    "precisions_2 = compute_precision_at_k(val['text_ids'], best_2_passages_faiss.tolist())\n",
    "recall_2 = compute_recall_at_k(val['text_ids'], best_2_passages_faiss.tolist())\n",
    "\n",
    "precisions_4 = compute_precision_at_k(val['text_ids'], best_4_passages_faiss.tolist())\n",
    "recall_4 = compute_recall_at_k(val['text_ids'], best_4_passages_faiss.tolist())\n",
    "\n",
    "precisions_5 = compute_precision_at_k(val['text_ids'], best_5_passages_faiss.tolist())\n",
    "recall_5 = compute_recall_at_k(val['text_ids'], best_5_passages_faiss.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 997
    },
    "id": "xJD0aVPo_fxI",
    "outputId": "4878c3eb-e84c-47c0-c5d5-d3feeeb36581"
   },
   "outputs": [],
   "source": [
    "precisions = [precisions_1, precisions_2, precisions_3, precisions_4, precisions_5]\n",
    "recalls = [recall_1, recall_2, recall_3, recall_4, recall_5]\n",
    "plot_retrieval(precisions, \"k\", \"Precision\",[1, 2, 3, 4, 5])\n",
    "plot_retrieval(recalls, \"k\", \"Recall\",[1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVnw7ZYBWIcm"
   },
   "source": [
    "Remarque sur Faiss\n",
    "\n",
    "- Exécution très rapide avec recherche par lot.\n",
    "- On obtient les mêmes résultats en précision et rappel. Ce qui n'est pas étonnant, étant donné que dans les deux méthodes, nous utilisons la similarité cosinus et les même plongements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9w2YJOqflmzO"
   },
   "source": [
    "### 3.3 Prommpt et Génération des réponses \n",
    "\n",
    "Nous allons maintenant générer les réponses aux questions du jeu de validation en utilisant les passages récupérés. Pour cela, nous concaténerons les passages pertinents avec la question selon un certain prompt avant de les soumettre au modèle de génération.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "mIlPHAg1lmzO"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "prompt_in_chat_format = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"Using only the information provided in the context, provide a on sentence short direct answer to the question.\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Context:\n",
    "{context}\n",
    "---\n",
    "Here is the question you need to answer.\n",
    "\n",
    "Question: {question}\"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Utilisé lors du Fine Tune pour reduire la memoire\n",
    "# RAG_PROMPT_TEMPLATE = tokenizer_lora.apply_chat_template(\n",
    "#     prompt_in_chat_format, tokenize=False, add_generation_prompt=True\n",
    "# )\n",
    "\n",
    "RAG_PROMPT_TEMPLATE = tokenizer_reader.apply_chat_template(\n",
    "    prompt_in_chat_format, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# END TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3fjaV6l_fxJ",
    "outputId": "621b96bb-bb2b-4bf8-ad28-9da4176f4dba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "Using only the information provided in the context, provide a on sentence short direct answer to the question.<|end|>\n",
      "<|user|>\n",
      "Context:\n",
      "{context}\n",
      "---\n",
      "Here is the question you need to answer.\n",
      "\n",
      "Question: {question}<|end|>\n",
      "<|assistant|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(RAG_PROMPT_TEMPLATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "cA7Z3CZDInQC"
   },
   "outputs": [],
   "source": [
    "def add_context(passages):\n",
    "  context = \"\\nExtracted documents:\\n\"\n",
    "  context += \"\".join(\n",
    "      [f\"Document {str(row)}:::\\n\" + text[\"text\"].iloc[row] for row in passages ]\n",
    "  )\n",
    "  return context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "cNhR-yWJBdOl"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "def create_prompt_context(questions,passages):\n",
    "\n",
    "  questions_context = [\n",
    "      #crée le prompt pour chaque question\n",
    "      RAG_PROMPT_TEMPLATE.format(\n",
    "          question=question,\n",
    "          context=add_context(passages[idx])\n",
    "      )\n",
    "      for idx, question in enumerate(questions)\n",
    "  ]\n",
    "  return questions_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Ri5Fi6ZCLx9O"
   },
   "outputs": [],
   "source": [
    "questions_prompt_1 = create_prompt_context(val[\"question\"], best_1_passages_faiss)\n",
    "questions_prompt_2 = create_prompt_context(val[\"question\"], best_2_passages_faiss)\n",
    "questions_prompt_3 = create_prompt_context(val[\"question\"], best_3_passages_faiss)\n",
    "questions_prompt_4 = create_prompt_context(val[\"question\"], best_4_passages_faiss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J16S8gKn_fxJ"
   },
   "source": [
    "Exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "sAQw5XuB3p0Y",
    "outputId": "94bbf0b4-f217-46b2-9ece-921dabd30242"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<|system|>\\nUsing only the information provided in the context, provide a on sentence short direct answer to the question.<|end|>\\n<|user|>\\nContext:\\n\\nExtracted documents:\\nDocument 8865:::\\n  Carbapenems are structurally similar to penicillins, but with a carbon atom replacing the sulfur atom in position 1. They are biosynthesized through a series of steps involving the condensation of malonyl-CoA with glutamate-5-semialdehyde, followed by the formation of the β-lactam and saturated carbapenam core.Document 5333:::\\n  Carbapenems are a class of highly effective antibiotic agents commonly used for the treatment of severe or high-risk bacterial infections. They are usually reserved for known or suspected multidrug-resistant (MDR) bacterial infections and have a broader spectrum of activity compared to most cephalosporins and penicillins.Document 2651:::\\n  The growing prevalence of carbapenem-resistant Enterobacteriaceae has led to a renaissance of the use of antibiotics such as colistin. Pseudomonas aeruginosa and Acinetobacter baumannii are also resistant to carbapenems due to their expression of a wide range of resistance mechanisms, including beta lactamases and efflux pumps.\\n---\\nHere is the question you need to answer.\\n\\nQuestion: What is the key difference in the structure of carbapenems compared to penicillins?<|end|>\\n<|assistant|>\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_prompt_3[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yciS3tYxlmzO"
   },
   "source": [
    "### 3.4 Évaluation des réponses \n",
    "Nous allons évaluer les réponses générées par rapport aux réponses attendues sur le jeu de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "UWjmqRF5BSJt"
   },
   "outputs": [],
   "source": [
    "READER_LLM = pipeline(\n",
    "    model=model_reader,\n",
    "    tokenizer=tokenizer_reader,\n",
    "    task=\"text-generation\",\n",
    "    do_sample=True,\n",
    "    temperature=0.2, # Température basse pour la génération\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=False,\n",
    "    device= 0 if DEVICE == \"cuda\" else -1,\n",
    "    max_new_tokens=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "FRax476YlmzO"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "def evaluate_rag(val,set_questions, READER):\n",
    "  results = []\n",
    "  #dataset ground truth\n",
    "  df_true = val[[\"id\", \"answer\"]]\n",
    "  for set_k in set_questions :\n",
    "    pred = []\n",
    "    questions = set_k[0]\n",
    "    k = set_k[1]\n",
    "    print(f\"Porcessing k = {k}\")\n",
    "\n",
    "    for question in questions :\n",
    "      #génération de la réponse\n",
    "      pred.append(READER(question)[0][\"generated_text\"])\n",
    "\n",
    "    #dataset prediction\n",
    "    df_pred = pd.DataFrame({\"id\": val[\"id\"], \"answer\": pred})\n",
    "\n",
    "    bleu_1 = evaluate_bleu(df_true, df_pred, 1)\n",
    "    bleu_2 = evaluate_bleu(df_true, df_pred, 2)\n",
    "\n",
    "    del df_pred\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    results.append([k,bleu_1, bleu_2])\n",
    "\n",
    "  return results\n",
    "# END TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "uI7hdAtXPMeW"
   },
   "outputs": [],
   "source": [
    "set_questions = [[questions_prompt_1,1], [questions_prompt_2,2], [questions_prompt_3,3], [questions_prompt_4,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "vcD5iE673-OE",
    "outputId": "853c6ba7-7c8a-4a2c-dfc9-135f3dc65619"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcessing k = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcessing k = 2\n",
      "Porcessing k = 3\n",
      "Porcessing k = 4\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_rag(val,set_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8q9nbK1KNu9i",
    "outputId": "07cbc02e-a52a-47fa-ca86-da7869c19a72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu score pour k = 1\n",
      "BLEU-1: 0.3489355885101853\n",
      "BLEU-2: 0.2145229330762801\n",
      "Bleu score pour k = 2\n",
      "BLEU-1: 0.3805855055461511\n",
      "BLEU-2: 0.252961288648296\n",
      "Bleu score pour k = 3\n",
      "BLEU-1: 0.4205482663894729\n",
      "BLEU-2: 0.2782441287195915\n",
      "Bleu score pour k = 4\n",
      "BLEU-1: 0.44278362113848874\n",
      "BLEU-2: 0.2966836680092076\n"
     ]
    }
   ],
   "source": [
    "for res in results :\n",
    "  print(f\"Bleu score pour k = {res[0]}\")\n",
    "  print(f\"BLEU-1: {res[1]}\")\n",
    "  print(f\"BLEU-2: {res[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eq0OgKH2yoi1"
   },
   "source": [
    "-> Bleu score pour k = 1\n",
    "BLEU-1: 0.3489355885101853\n",
    "BLEU-2: 0.2145229330762801\n",
    "\n",
    "-> Bleu score pour k = 2\n",
    "BLEU-1: 0.3805855055461511\n",
    "BLEU-2: 0.252961288648296\n",
    "\n",
    "-> Bleu score pour k = 3\n",
    "BLEU-1: 0.4205482663894729\n",
    "BLEU-2: 0.2782441287195915\n",
    "\n",
    "-> Bleu score pour k = 4\n",
    "BLEU-1: 0.44278362113848874\n",
    "BLEU-2: 0.2966836680092076"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81uMlx3_Kf4X",
    "outputId": "29fac328-8192-4832-ec73-12c3ea78fd4c"
   },
   "source": [
    "Remarque:\n",
    "\n",
    "Basé sur les scores de génération, on peut conlure que le nombre optimal est de 4. Cela montre qu'il est préférable d'ajouter plus d'informations au risque d'ajouter du bruit. Le modèle LLM pourra lui même identifier la bonne information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgZFmQpvWIco"
   },
   "source": [
    "### 3.5 Sortie en csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "7H4Bt-H8_fxK"
   },
   "outputs": [],
   "source": [
    "best_4_passages_faiss_test = retrieve_passages_faiss(test[\"question\"].to_list(), index, 4, tokenizer, model)\n",
    "questions_prompt_4_test = create_prompt_context(test[\"question\"], best_4_passages_faiss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wc5kgTZp_fxK"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "def create_submission(questions):\n",
    "\n",
    "  date = datetime.datetime.now()\n",
    "  date_str = str(date)[:10]\n",
    "  results = []\n",
    "  question_ids = test[\"id\"]\n",
    "\n",
    "  for question in questions :\n",
    "    pred = READER_LLM(question)[0][\"generated_text\"]\n",
    "    results.append(pred)\n",
    "  #format soumissions\n",
    "  df_submission = pd.DataFrame({\n",
    "        'id': question_ids,\n",
    "        'answer': results\n",
    "    })\n",
    "\n",
    "  df_submission.to_csv(f\"submissions_{date_str}\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "OvLqCexg_fxL"
   },
   "outputs": [],
   "source": [
    "create_submission(questions_prompt_4_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXAFT57QlmzP"
   },
   "source": [
    "## 4. Nouvelle methode\n",
    "\n",
    "### 4.1. État de l'art \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y00x9leClmzQ"
   },
   "source": [
    "Synthèse:\n",
    "\n",
    "Le domaine de la génération augmentée par recherche (RAG), s'est vu améliorer de deux approches différentes. L'une en se contentant d'améliorer la structure initiale des RAG, les RAG avancées et l'autre en  y ajoutant des nouveaux éléments, les RAG modulaires. \n",
    "\n",
    "Des RAG avancées nous pouvons tirer la méthode du reranking, consitant à trier les résultats d'une première recherche dense, à l'aide de modèle Cross-encoder par exemple. Les plus récentes méthodes proposes le reranking LLM. De plus, nous pouvons noter, les techniques portant sur l'enrechissement de la requête, avec la méthode de Sub-Query. Elle consite à diviser la requête en sous requête pour contextualiser davantage la question. En effectuant plusieurs recherches de documents en parrallèle sur ces sous questions nous obtenons des résulatats enrichies.  \n",
    "\n",
    "Pour ce qui est des RAG modulaires, nous pouvons noter les techniques adaptatives tel que Self-RAG ou encore les techniques itératives. En s'appuiant sur la technique d'augmentation de la requête avec HYDE, il est possible de modifier la réponse et la recherche jusqu'à obtenir une réponse correcte, via un JUGE LLM ou autre mesure. \n",
    "\n",
    "Un dernier point concerne l'affinage des modèles conséquents à l'aide de technique tel que LORA. Permettant de réduire le besoin en ressource pour fine tune le modèle générateur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1v1PxzjlmzQ"
   },
   "source": [
    "Références: Listez vos références de manière appropriée (4-5 parmi les meilleures approches)\n",
    "\n",
    "- 1) Retrieval-Augmented Generation for Large Language Models: A Survey  -> Résume les méthodes RAG avancés et modualaire\n",
    "- 2) Precise Zero-Shot Dense Retrieval without Relevance Labels -> Présente HYDE\n",
    "- 3) ARAGOG: Advanced RAG Output Grading   -> Présente la combinaison HYDE + reranking LLM\n",
    "- 4) Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy  -> présente une méthode itération \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmC52uiQlmzQ"
   },
   "source": [
    "### 4.2. Description de notre méthode \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description :\n",
    "\n",
    "Dans un premier temps, nous entraînons un modèle génératif sur le training set pour qu'il puisse répondre de manière précise et pertinente en fonction des passages extraits. Pour cela, nous utilisons la méthode LoRA, qui permet une fine-tuning sur peu de ressources. Par ailleurs, nous avons exploré l'entraînement d'un modèle d'embedding en appliquant une approche contrastive sur des exemples positifs et négatifs. Cependant, cette méthode n'a pas produit les résultats escomptés, nous conduisant à nous concentrer sur d'autres aspects de l'architecture.\n",
    "\n",
    "Ensuite, nous mettons en œuvre deux techniques distinctes d'augmentation de requêtes en parallèle. D'une part, nous utilisons Hyde pour générer des documents hypothétiques et effectuer une recherche sur ces derniers. D'autre part, nous décomposons la requête initiale en deux ou trois sous-questions grâce à un notre modèle génératif et effectuons une recherche sur ces sous-questions. Nous avons constaté que ces deux méthodes identifient des documents complémentaires en termes de pertinence. Pour exploiter cette synergie, nous combinons les résultats des deux approches. Enfin, nous intégrons un reranking des documents à l'aide du cross-encoder ms-marco-MiniLM-L-6-v.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o03MTMTylmzQ"
   },
   "source": [
    "### 4.3. Implémentation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A) Fine-tuning du modèle génératif avec LORA\n",
    "Le **fine-tuning du modèle génératif avec LoRA** (*Low-Rank Adaptation*) est une méthode d’adaptation efficace qui réduit le nombre de paramètres à entraîner en insérant des matrices de faible rang dans les couches du modèle pré-entraîné. Cette approche permet de modifier le comportement du modèle sans mettre à jour l’ensemble de ses poids, rendant l'entraînement plus rapide, moins gourmand en mémoire et mieux adapté aux ressources limitées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "vDUn-fBqlmzQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.31s/it]\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Reduis nombre de batch pour reduire le cout en memoire lors du fine-tuning\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "model_lora = AutoModelForCausalLM.from_pretrained(\n",
    "    READER_MODEL_NAME, \n",
    "    device_map =\"auto\"\n",
    ")\n",
    "\n",
    "tokenizer_lora = AutoTokenizer.from_pretrained(READER_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft in ./.venv/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.10/site-packages (from peft) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from peft) (24.2)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.10/site-packages (from peft) (6.1.0)\n",
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.10/site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in ./.venv/lib/python3.10/site-packages (from peft) (2.5.1)\n",
      "Requirement already satisfied: transformers in ./.venv/lib/python3.10/site-packages (from peft) (4.46.3)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.10/site-packages (from peft) (4.67.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in ./.venv/lib/python3.10/site-packages (from peft) (1.1.1)\n",
      "Requirement already satisfied: safetensors in ./.venv/lib/python3.10/site-packages (from peft) (0.4.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in ./.venv/lib/python3.10/site-packages (from peft) (0.26.2)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.9.0)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in ./.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.10/site-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in ./.venv/lib/python3.10/site-packages (from transformers->peft) (0.20.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# On identifier les modules cibles \n",
    "# On va fine-tune les dernière couches\n",
    "target_modules = [\n",
    "    f\"layers.{i}.self_attn.qkv_proj\" for i in range(26, 32)\n",
    "] + [\n",
    "    f\"layers.{i}.self_attn.o_proj\" for i in range(26, 32)\n",
    "]\n",
    "\n",
    "# Configuration de LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=target_modules,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\"\n",
    ")\n",
    "\n",
    "# Appliquer LoRA au modèle\n",
    "model_lora = get_peft_model(model_lora, lora_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On gele les poids que nous allons pas entrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geler les paramètres principaux\n",
    "for name, param in model_lora.named_parameters():\n",
    "    if not \"lora\" in name:\n",
    "        param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paramètres entraînables avec LoRA :\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.26.self_attn.qkv_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.26.self_attn.qkv_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.27.self_attn.qkv_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.27.self_attn.qkv_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.28.self_attn.qkv_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.28.self_attn.qkv_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.29.self_attn.qkv_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.29.self_attn.qkv_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.30.self_attn.qkv_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.30.self_attn.qkv_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.31.self_attn.qkv_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.31.self_attn.qkv_proj.lora_B.default.weight\n"
     ]
    }
   ],
   "source": [
    "# Vérifier les paramètres entraînables\n",
    "print(\"Paramètres entraînables avec LoRA :\")\n",
    "for name, param in model_lora.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant recupérer nos données d'entrainement en utilisant le prompt précédent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertie les indices en données numerique et pas string\n",
    "train_textids = train[\"text_ids\"].apply(lambda x: [int(i) for i in x.replace(\"[\", \"\").replace(\"]\", \"\").split(\" \") if i.isdigit()])\n",
    "# Crée une colonne avec les prompt de chaque question\n",
    "trainset_prompt = create_prompt_context(train[\"question\"], train_textids)\n",
    "train[\"prompt\"] = trainset_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formate nos données d'entrainement pour qu'elles soient utilisable our un model Causal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(row):\n",
    "    input_text = row['prompt']\n",
    "    target_text = row['answer']\n",
    "    full_text = input_text + target_text\n",
    "    return pd.Series({\"input_text\": input_text, \"target_text\": target_text, \"full_text\": full_text})\n",
    "\n",
    "formatted_train = train.apply(format_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre maximum de tokens : 598\n"
     ]
    }
   ],
   "source": [
    "# Initialisation des compteurs\n",
    "max_tokens = 0\n",
    "\n",
    "# Parcourir chaque ligne pour analyser les tokens\n",
    "for idx, row in formatted_train.iterrows():\n",
    "    tokenized = tokenizer_lora(\n",
    "        row[\"full_text\"],\n",
    "        truncation=False,  # Pas de troncature pour capturer toute la longueur\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    num_tokens = len(tokenized[\"input_ids\"][0])\n",
    "    \n",
    "    # Mise à jour du maximum de tokens\n",
    "    if num_tokens > max_tokens:\n",
    "        max_tokens = num_tokens\n",
    "\n",
    "# Affichage du résultat\n",
    "print(f\"Nombre maximum de tokens : {max_tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(row):\n",
    "    # Tokeniser les questions + réponses ensemble pour le modèle causal\n",
    "    tokens = tokenizer_lora(\n",
    "        row[\"full_text\"],  # Texte complet (prompt + réponse)\n",
    "        max_length=600,  # Limite selon le max de token pour éviter les séquences trop longues\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    tokens[\"labels\"] = tokens[\"input_ids\"].copy()  # Les labels sont identiques aux entrées\n",
    "    return tokens\n",
    "\n",
    "# Appliquer la fonction ligne par ligne\n",
    "tokenized_train = formatted_train.apply(lambda row: tokenize_data(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_train,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=lambda x: {k: torch.tensor([d[k] for d in x]) for k in x[0]}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On passe à l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/.venv/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "# On inclut uniquement les paramètres non gelés\n",
    "optimizer = AdamW(\n",
    "    [param for param in model_lora.parameters() if param.requires_grad],\n",
    "    lr=5e-5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "# Scheduler de taux d'apprentissage (learning rate scheduler) \n",
    "# Utile pour ajuster dynamiquement le taux d'apprentissage pendant l'entraînement\n",
    "\n",
    "num_training_steps = len(train_dataloader) * 3  # 3 époques\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/657 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Époque 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/657 [00:28<2:13:55, 12.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2/219 - Loss moyenne : 4.5233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/657 [00:32<55:01,  5.06s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4/219 - Loss moyenne : 4.7228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/657 [00:35<32:44,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6/219 - Loss moyenne : 4.4047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/657 [00:38<24:00,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8/219 - Loss moyenne : 4.4222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10/657 [00:41<20:08,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 10/219 - Loss moyenne : 4.4738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 12/657 [00:44<18:18,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 12/219 - Loss moyenne : 4.4994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 14/657 [00:47<17:28,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 14/219 - Loss moyenne : 3.8028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 16/657 [00:50<17:02,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 16/219 - Loss moyenne : 4.3346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 18/657 [00:53<16:52,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 18/219 - Loss moyenne : 3.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 20/657 [00:56<16:44,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 20/219 - Loss moyenne : 4.0348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 22/657 [01:00<16:39,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 22/219 - Loss moyenne : 4.0068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 24/657 [01:03<16:38,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 24/219 - Loss moyenne : 3.9408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 26/657 [01:06<16:39,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 26/219 - Loss moyenne : 3.6354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 28/657 [01:09<16:35,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 28/219 - Loss moyenne : 3.7012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 30/657 [01:12<16:34,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 30/219 - Loss moyenne : 3.4117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 32/657 [01:15<16:33,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 32/219 - Loss moyenne : 3.2354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 34/657 [01:19<16:31,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 34/219 - Loss moyenne : 3.2838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 36/657 [01:22<16:30,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 36/219 - Loss moyenne : 3.1354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 38/657 [01:25<16:29,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 38/219 - Loss moyenne : 3.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 40/657 [01:28<16:27,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 40/219 - Loss moyenne : 2.7015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 42/657 [01:31<16:24,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 42/219 - Loss moyenne : 2.5704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 44/657 [01:35<16:30,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 44/219 - Loss moyenne : 2.5515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 46/657 [01:38<16:26,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 46/219 - Loss moyenne : 2.2592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 48/657 [01:41<16:25,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 48/219 - Loss moyenne : 2.2297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 50/657 [01:44<16:24,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50/219 - Loss moyenne : 1.8918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 52/657 [01:48<16:23,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 52/219 - Loss moyenne : 1.8101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 54/657 [01:51<16:18,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 54/219 - Loss moyenne : 1.5949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 56/657 [01:54<16:12,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 56/219 - Loss moyenne : 1.4054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 58/657 [01:57<16:09,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 58/219 - Loss moyenne : 1.2492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 60/657 [02:00<15:59,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 60/219 - Loss moyenne : 1.0164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 62/657 [02:04<15:53,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 62/219 - Loss moyenne : 0.9319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 64/657 [02:07<15:50,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 64/219 - Loss moyenne : 0.8539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 66/657 [02:10<15:45,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 66/219 - Loss moyenne : 0.6679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 68/657 [02:13<15:42,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 68/219 - Loss moyenne : 0.6664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 70/657 [02:16<15:39,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 70/219 - Loss moyenne : 0.6185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 72/657 [02:20<15:35,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 72/219 - Loss moyenne : 0.5870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 74/657 [02:23<15:32,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 74/219 - Loss moyenne : 0.5840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 76/657 [02:26<15:30,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 76/219 - Loss moyenne : 0.5014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 78/657 [02:29<15:28,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 78/219 - Loss moyenne : 0.5322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 80/657 [02:33<15:24,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 80/219 - Loss moyenne : 0.5488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 82/657 [02:36<15:21,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 82/219 - Loss moyenne : 0.5129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 84/657 [02:39<15:19,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 84/219 - Loss moyenne : 0.5233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 86/657 [02:42<15:19,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 86/219 - Loss moyenne : 0.5187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 88/657 [02:45<15:20,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 88/219 - Loss moyenne : 0.4994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 90/657 [02:49<15:23,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 90/219 - Loss moyenne : 0.5071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 92/657 [02:52<15:23,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 92/219 - Loss moyenne : 0.5105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 94/657 [02:55<15:23,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 94/219 - Loss moyenne : 0.5314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 96/657 [02:59<15:18,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 96/219 - Loss moyenne : 0.4962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 98/657 [03:02<15:17,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 98/219 - Loss moyenne : 0.4808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 100/657 [03:05<15:14,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100/219 - Loss moyenne : 0.5094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 102/657 [03:08<15:17,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 102/219 - Loss moyenne : 0.4975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 104/657 [03:12<15:16,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 104/219 - Loss moyenne : 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 106/657 [03:15<15:18,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 106/219 - Loss moyenne : 0.4971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 108/657 [03:18<15:16,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 108/219 - Loss moyenne : 0.4751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 110/657 [03:22<15:09,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 110/219 - Loss moyenne : 0.5001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 112/657 [03:25<15:05,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 112/219 - Loss moyenne : 0.5069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 114/657 [03:28<14:58,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 114/219 - Loss moyenne : 0.4965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 116/657 [03:32<14:53,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 116/219 - Loss moyenne : 0.4917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 118/657 [03:35<14:51,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 118/219 - Loss moyenne : 0.5417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 120/657 [03:38<14:44,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 120/219 - Loss moyenne : 0.4836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 122/657 [03:42<14:41,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 122/219 - Loss moyenne : 0.5229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 124/657 [03:45<14:35,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 124/219 - Loss moyenne : 0.5191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 126/657 [03:48<14:29,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 126/219 - Loss moyenne : 0.5253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 128/657 [03:51<14:26,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 128/219 - Loss moyenne : 0.4572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 130/657 [03:55<14:24,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 130/219 - Loss moyenne : 0.4764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 132/657 [03:58<14:23,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 132/219 - Loss moyenne : 0.5536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 134/657 [04:01<14:23,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 134/219 - Loss moyenne : 0.5068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 136/657 [04:05<14:17,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 136/219 - Loss moyenne : 0.4764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 138/657 [04:08<14:18,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 138/219 - Loss moyenne : 0.5164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 140/657 [04:11<14:16,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 140/219 - Loss moyenne : 0.5192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 142/657 [04:15<14:14,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 142/219 - Loss moyenne : 0.5099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 144/657 [04:18<14:14,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 144/219 - Loss moyenne : 0.4966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 146/657 [04:21<14:11,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 146/219 - Loss moyenne : 0.5013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 148/657 [04:25<14:08,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 148/219 - Loss moyenne : 0.5196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 150/657 [04:28<14:02,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 150/219 - Loss moyenne : 0.5101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 152/657 [04:31<14:00,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 152/219 - Loss moyenne : 0.5022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 154/657 [04:35<13:57,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 154/219 - Loss moyenne : 0.4729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 156/657 [04:38<13:54,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 156/219 - Loss moyenne : 0.4756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 158/657 [04:41<13:53,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 158/219 - Loss moyenne : 0.4987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 160/657 [04:45<13:51,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 160/219 - Loss moyenne : 0.4864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 162/657 [04:48<13:44,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 162/219 - Loss moyenne : 0.5069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 164/657 [04:51<13:35,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 164/219 - Loss moyenne : 0.4596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 166/657 [04:54<13:28,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 166/219 - Loss moyenne : 0.5005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 168/657 [04:58<13:20,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 168/219 - Loss moyenne : 0.4684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 170/657 [05:01<13:12,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 170/219 - Loss moyenne : 0.4514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 172/657 [05:04<13:07,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 172/219 - Loss moyenne : 0.4503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 174/657 [05:07<13:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 174/219 - Loss moyenne : 0.4700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 176/657 [05:11<12:55,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 176/219 - Loss moyenne : 0.4981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 178/657 [05:14<12:48,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 178/219 - Loss moyenne : 0.5094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 180/657 [05:17<12:44,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 180/219 - Loss moyenne : 0.4865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 182/657 [05:20<12:40,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 182/219 - Loss moyenne : 0.4712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 184/657 [05:23<12:36,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 184/219 - Loss moyenne : 0.4600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 186/657 [05:27<12:33,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 186/219 - Loss moyenne : 0.4618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 188/657 [05:30<12:30,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 188/219 - Loss moyenne : 0.4408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 190/657 [05:33<12:27,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 190/219 - Loss moyenne : 0.4308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 192/657 [05:36<12:23,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 192/219 - Loss moyenne : 0.4729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 194/657 [05:39<12:20,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 194/219 - Loss moyenne : 0.4193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 196/657 [05:43<12:17,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 196/219 - Loss moyenne : 0.4174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 198/657 [05:46<12:14,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 198/219 - Loss moyenne : 0.4597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 200/657 [05:49<12:11,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200/219 - Loss moyenne : 0.4735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 202/657 [05:52<12:07,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 202/219 - Loss moyenne : 0.4773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 204/657 [05:55<12:05,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 204/219 - Loss moyenne : 0.4927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 206/657 [05:59<12:01,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 206/219 - Loss moyenne : 0.4502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 208/657 [06:02<11:58,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 208/219 - Loss moyenne : 0.4827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 210/657 [06:05<11:55,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 210/219 - Loss moyenne : 0.4420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 212/657 [06:08<11:52,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 212/219 - Loss moyenne : 0.4321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 214/657 [06:11<11:53,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 214/219 - Loss moyenne : 0.4923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 216/657 [06:15<11:51,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 216/219 - Loss moyenne : 0.4304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 218/657 [06:18<11:48,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 218/219 - Loss moyenne : 0.4634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 219/657 [06:19<09:39,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 219/219 - Loss moyenne : 0.2421\n",
      "Époque 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 221/657 [06:22<10:43,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2/219 - Loss moyenne : 0.3936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 223/657 [06:25<11:14,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4/219 - Loss moyenne : 0.4117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 225/657 [06:28<11:29,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6/219 - Loss moyenne : 0.4427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 227/657 [06:32<11:36,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8/219 - Loss moyenne : 0.4873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 229/657 [06:35<11:38,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 10/219 - Loss moyenne : 0.4125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 231/657 [06:38<11:41,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 12/219 - Loss moyenne : 0.5001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 233/657 [06:42<11:44,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 14/219 - Loss moyenne : 0.4352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 235/657 [06:45<11:51,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 16/219 - Loss moyenne : 0.4283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 237/657 [06:48<11:53,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 18/219 - Loss moyenne : 0.4246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 239/657 [06:52<11:49,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 20/219 - Loss moyenne : 0.4916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 241/657 [06:55<11:39,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 22/219 - Loss moyenne : 0.4675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 243/657 [06:58<11:31,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 24/219 - Loss moyenne : 0.4428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 245/657 [07:02<11:22,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 26/219 - Loss moyenne : 0.4317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 247/657 [07:05<11:13,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 28/219 - Loss moyenne : 0.4583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 249/657 [07:08<11:07,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 30/219 - Loss moyenne : 0.4374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 251/657 [07:11<11:00,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 32/219 - Loss moyenne : 0.4293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 253/657 [07:15<10:54,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 34/219 - Loss moyenne : 0.4138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 255/657 [07:18<10:52,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 36/219 - Loss moyenne : 0.4362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 257/657 [07:21<10:48,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 38/219 - Loss moyenne : 0.4016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 259/657 [07:24<10:44,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 40/219 - Loss moyenne : 0.3940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 261/657 [07:28<10:41,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 42/219 - Loss moyenne : 0.4459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 263/657 [07:31<10:39,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 44/219 - Loss moyenne : 0.4387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 265/657 [07:34<10:34,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 46/219 - Loss moyenne : 0.4323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 267/657 [07:37<10:31,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 48/219 - Loss moyenne : 0.4016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 269/657 [07:41<10:28,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50/219 - Loss moyenne : 0.4297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 271/657 [07:44<10:26,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 52/219 - Loss moyenne : 0.4178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 273/657 [07:47<10:22,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 54/219 - Loss moyenne : 0.4073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 275/657 [07:50<10:22,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 56/219 - Loss moyenne : 0.4777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 277/657 [07:54<10:18,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 58/219 - Loss moyenne : 0.4294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 279/657 [07:57<10:15,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 60/219 - Loss moyenne : 0.3922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 281/657 [08:00<10:15,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 62/219 - Loss moyenne : 0.4088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 283/657 [08:03<10:13,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 64/219 - Loss moyenne : 0.4301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 285/657 [08:07<10:10,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 66/219 - Loss moyenne : 0.4252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 287/657 [08:10<10:10,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 68/219 - Loss moyenne : 0.4049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 289/657 [08:13<10:10,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 70/219 - Loss moyenne : 0.4350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 291/657 [08:17<10:08,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 72/219 - Loss moyenne : 0.4227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 293/657 [08:20<10:08,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 74/219 - Loss moyenne : 0.4325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 295/657 [08:23<10:04,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 76/219 - Loss moyenne : 0.3821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 297/657 [08:27<09:59,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 78/219 - Loss moyenne : 0.4775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 299/657 [08:30<09:52,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 80/219 - Loss moyenne : 0.4167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 301/657 [08:33<09:47,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 82/219 - Loss moyenne : 0.4735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 303/657 [08:37<09:41,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 84/219 - Loss moyenne : 0.4190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 305/657 [08:40<09:36,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 86/219 - Loss moyenne : 0.3957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 307/657 [08:43<09:30,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 88/219 - Loss moyenne : 0.4204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 309/657 [08:46<09:27,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 90/219 - Loss moyenne : 0.4141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 311/657 [08:50<09:23,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 92/219 - Loss moyenne : 0.3832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 313/657 [08:53<09:20,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 94/219 - Loss moyenne : 0.4431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 315/657 [08:56<09:15,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 96/219 - Loss moyenne : 0.3823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 317/657 [08:59<09:11,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 98/219 - Loss moyenne : 0.3866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 319/657 [09:03<09:06,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100/219 - Loss moyenne : 0.4239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 321/657 [09:06<09:01,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 102/219 - Loss moyenne : 0.4066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 323/657 [09:09<08:59,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 104/219 - Loss moyenne : 0.3887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 325/657 [09:12<08:57,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 106/219 - Loss moyenne : 0.4197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 327/657 [09:16<08:54,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 108/219 - Loss moyenne : 0.3729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 329/657 [09:19<08:51,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 110/219 - Loss moyenne : 0.3667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 331/657 [09:22<08:48,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 112/219 - Loss moyenne : 0.4022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 333/657 [09:25<08:48,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 114/219 - Loss moyenne : 0.3825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 335/657 [09:29<08:45,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 116/219 - Loss moyenne : 0.4466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 337/657 [09:32<08:43,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 118/219 - Loss moyenne : 0.3984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 339/657 [09:35<08:41,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 120/219 - Loss moyenne : 0.3841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 341/657 [09:38<08:39,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 122/219 - Loss moyenne : 0.4113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 343/657 [09:42<08:38,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 124/219 - Loss moyenne : 0.4130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 345/657 [09:45<08:37,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 126/219 - Loss moyenne : 0.4342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 347/657 [09:48<08:35,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 128/219 - Loss moyenne : 0.3930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 349/657 [09:52<08:34,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 130/219 - Loss moyenne : 0.3807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 351/657 [09:55<08:29,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 132/219 - Loss moyenne : 0.3754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 353/657 [09:58<08:23,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 134/219 - Loss moyenne : 0.4190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 355/657 [10:02<08:17,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 136/219 - Loss moyenne : 0.4079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 357/657 [10:05<08:10,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 138/219 - Loss moyenne : 0.3731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 359/657 [10:08<08:04,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 140/219 - Loss moyenne : 0.3963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 361/657 [10:11<07:57,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 142/219 - Loss moyenne : 0.3853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 363/657 [10:15<07:52,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 144/219 - Loss moyenne : 0.3897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 365/657 [10:18<07:47,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 146/219 - Loss moyenne : 0.3964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 367/657 [10:21<07:44,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 148/219 - Loss moyenne : 0.4049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 369/657 [10:24<07:40,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 150/219 - Loss moyenne : 0.3843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 371/657 [10:27<07:37,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 152/219 - Loss moyenne : 0.3974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 373/657 [10:31<07:34,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 154/219 - Loss moyenne : 0.3731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 375/657 [10:34<07:31,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 156/219 - Loss moyenne : 0.4006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 377/657 [10:37<07:27,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 158/219 - Loss moyenne : 0.4249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 379/657 [10:40<07:24,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 160/219 - Loss moyenne : 0.3897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 381/657 [10:43<07:21,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 162/219 - Loss moyenne : 0.3899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 383/657 [10:47<07:18,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 164/219 - Loss moyenne : 0.3782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 385/657 [10:50<07:15,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 166/219 - Loss moyenne : 0.3766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 387/657 [10:53<07:11,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 168/219 - Loss moyenne : 0.3966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 389/657 [10:56<07:08,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 170/219 - Loss moyenne : 0.3624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 391/657 [10:59<07:05,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 172/219 - Loss moyenne : 0.3876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 393/657 [11:02<07:02,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 174/219 - Loss moyenne : 0.3792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 395/657 [11:06<06:59,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 176/219 - Loss moyenne : 0.3598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 397/657 [11:09<06:55,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 178/219 - Loss moyenne : 0.3844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 399/657 [11:12<06:52,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 180/219 - Loss moyenne : 0.3734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 401/657 [11:15<06:49,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 182/219 - Loss moyenne : 0.3771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 403/657 [11:18<06:46,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 184/219 - Loss moyenne : 0.3784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 405/657 [11:22<06:43,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 186/219 - Loss moyenne : 0.3645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 407/657 [11:25<06:40,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 188/219 - Loss moyenne : 0.3675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 409/657 [11:28<06:36,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 190/219 - Loss moyenne : 0.3820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 411/657 [11:31<06:33,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 192/219 - Loss moyenne : 0.3712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 413/657 [11:34<06:30,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 194/219 - Loss moyenne : 0.3738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 415/657 [11:38<06:26,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 196/219 - Loss moyenne : 0.3839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 417/657 [11:41<06:24,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 198/219 - Loss moyenne : 0.3134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 419/657 [11:44<06:20,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200/219 - Loss moyenne : 0.3841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 421/657 [11:47<06:17,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 202/219 - Loss moyenne : 0.3504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 423/657 [11:51<06:15,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 204/219 - Loss moyenne : 0.3911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 425/657 [11:54<06:14,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 206/219 - Loss moyenne : 0.3692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 427/657 [11:57<06:11,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 208/219 - Loss moyenne : 0.3499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 429/657 [12:00<06:10,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 210/219 - Loss moyenne : 0.4164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 431/657 [12:04<06:09,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 212/219 - Loss moyenne : 0.3938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 433/657 [12:07<06:07,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 214/219 - Loss moyenne : 0.3572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 435/657 [12:10<06:04,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 216/219 - Loss moyenne : 0.3505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 437/657 [12:13<06:03,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 218/219 - Loss moyenne : 0.3436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 438/657 [12:14<04:57,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 219/219 - Loss moyenne : 0.2084\n",
      "Époque 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 440/657 [12:17<05:30,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2/219 - Loss moyenne : 0.3622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 442/657 [12:21<05:44,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4/219 - Loss moyenne : 0.3130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 444/657 [12:24<05:50,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6/219 - Loss moyenne : 0.3652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 446/657 [12:28<05:48,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8/219 - Loss moyenne : 0.3561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 448/657 [12:31<05:44,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 10/219 - Loss moyenne : 0.3787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 450/657 [12:34<05:38,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 12/219 - Loss moyenne : 0.3732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 452/657 [12:37<05:33,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 14/219 - Loss moyenne : 0.3622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 454/657 [12:41<05:27,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 16/219 - Loss moyenne : 0.3611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 456/657 [12:44<05:22,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 18/219 - Loss moyenne : 0.3594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 458/657 [12:47<05:19,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 20/219 - Loss moyenne : 0.3470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 460/657 [12:50<05:15,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 22/219 - Loss moyenne : 0.3569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 462/657 [12:53<05:12,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 24/219 - Loss moyenne : 0.3460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 464/657 [12:57<05:08,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 26/219 - Loss moyenne : 0.3796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 466/657 [13:00<05:05,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 28/219 - Loss moyenne : 0.3323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 468/657 [13:03<05:02,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 30/219 - Loss moyenne : 0.3430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 470/657 [13:06<04:59,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 32/219 - Loss moyenne : 0.3194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 472/657 [13:09<04:55,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 34/219 - Loss moyenne : 0.3299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 474/657 [13:12<04:52,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 36/219 - Loss moyenne : 0.3457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 476/657 [13:16<04:49,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 38/219 - Loss moyenne : 0.3415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 478/657 [13:19<04:46,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 40/219 - Loss moyenne : 0.3849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 480/657 [13:22<04:43,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 42/219 - Loss moyenne : 0.3023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 482/657 [13:25<04:39,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 44/219 - Loss moyenne : 0.3504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 484/657 [13:28<04:36,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 46/219 - Loss moyenne : 0.3580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 486/657 [13:32<04:33,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 48/219 - Loss moyenne : 0.3248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 488/657 [13:35<04:30,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 50/219 - Loss moyenne : 0.3587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 490/657 [13:38<04:27,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 52/219 - Loss moyenne : 0.3382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 492/657 [13:41<04:23,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 54/219 - Loss moyenne : 0.3246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 494/657 [13:44<04:20,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 56/219 - Loss moyenne : 0.3320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 496/657 [13:48<04:17,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 58/219 - Loss moyenne : 0.3296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 498/657 [13:51<04:14,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 60/219 - Loss moyenne : 0.3137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 500/657 [13:54<04:11,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 62/219 - Loss moyenne : 0.3051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 502/657 [13:57<04:08,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 64/219 - Loss moyenne : 0.3341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 504/657 [14:00<04:04,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 66/219 - Loss moyenne : 0.3198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 506/657 [14:04<04:01,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 68/219 - Loss moyenne : 0.2838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 508/657 [14:07<03:58,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 70/219 - Loss moyenne : 0.3446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 510/657 [14:10<03:55,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 72/219 - Loss moyenne : 0.3116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 512/657 [14:13<03:52,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 74/219 - Loss moyenne : 0.3233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 514/657 [14:16<03:48,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 76/219 - Loss moyenne : 0.3126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 516/657 [14:20<03:45,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 78/219 - Loss moyenne : 0.3021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 518/657 [14:23<03:42,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 80/219 - Loss moyenne : 0.3176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 520/657 [14:26<03:39,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 82/219 - Loss moyenne : 0.3164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 522/657 [14:29<03:36,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 84/219 - Loss moyenne : 0.3739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 524/657 [14:32<03:32,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 86/219 - Loss moyenne : 0.3205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 526/657 [14:36<03:29,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 88/219 - Loss moyenne : 0.3183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 528/657 [14:39<03:26,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 90/219 - Loss moyenne : 0.3396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 530/657 [14:42<03:24,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 92/219 - Loss moyenne : 0.3166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 532/657 [14:45<03:22,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 94/219 - Loss moyenne : 0.3070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 534/657 [14:49<03:19,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 96/219 - Loss moyenne : 0.2894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 536/657 [14:52<03:17,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 98/219 - Loss moyenne : 0.3099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 538/657 [14:55<03:14,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100/219 - Loss moyenne : 0.2823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 540/657 [14:58<03:11,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 102/219 - Loss moyenne : 0.3388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 542/657 [15:02<03:09,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 104/219 - Loss moyenne : 0.3061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 544/657 [15:05<03:07,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 106/219 - Loss moyenne : 0.2840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 546/657 [15:08<03:04,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 108/219 - Loss moyenne : 0.3104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 548/657 [15:12<02:59,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 110/219 - Loss moyenne : 0.2923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 550/657 [15:15<02:55,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 112/219 - Loss moyenne : 0.2357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 552/657 [15:18<02:51,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 114/219 - Loss moyenne : 0.3290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 554/657 [15:21<02:47,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 116/219 - Loss moyenne : 0.2955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 556/657 [15:25<02:43,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 118/219 - Loss moyenne : 0.3097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 558/657 [15:28<02:39,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 120/219 - Loss moyenne : 0.2997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 560/657 [15:31<02:35,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 122/219 - Loss moyenne : 0.2987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 562/657 [15:34<02:32,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 124/219 - Loss moyenne : 0.2853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 564/657 [15:37<02:28,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 126/219 - Loss moyenne : 0.3285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 566/657 [15:41<02:25,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 128/219 - Loss moyenne : 0.3398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 568/657 [15:44<02:22,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 130/219 - Loss moyenne : 0.3003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 570/657 [15:47<02:19,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 132/219 - Loss moyenne : 0.2954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 572/657 [15:50<02:16,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 134/219 - Loss moyenne : 0.3401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 574/657 [15:53<02:12,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 136/219 - Loss moyenne : 0.3472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 576/657 [15:57<02:09,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 138/219 - Loss moyenne : 0.3255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 578/657 [16:00<02:06,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 140/219 - Loss moyenne : 0.3050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 580/657 [16:03<02:03,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 142/219 - Loss moyenne : 0.2883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 582/657 [16:06<02:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 144/219 - Loss moyenne : 0.2685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 584/657 [16:09<01:56,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 146/219 - Loss moyenne : 0.2920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 586/657 [16:13<01:53,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 148/219 - Loss moyenne : 0.2934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 588/657 [16:16<01:50,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 150/219 - Loss moyenne : 0.2906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 590/657 [16:19<01:47,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 152/219 - Loss moyenne : 0.3082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 592/657 [16:22<01:43,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 154/219 - Loss moyenne : 0.3056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 594/657 [16:25<01:40,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 156/219 - Loss moyenne : 0.2966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 596/657 [16:29<01:37,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 158/219 - Loss moyenne : 0.3101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 598/657 [16:32<01:34,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 160/219 - Loss moyenne : 0.3292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 600/657 [16:35<01:31,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 162/219 - Loss moyenne : 0.3347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 602/657 [16:38<01:28,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 164/219 - Loss moyenne : 0.3104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 604/657 [16:42<01:25,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 166/219 - Loss moyenne : 0.2948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 606/657 [16:45<01:22,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 168/219 - Loss moyenne : 0.3305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 608/657 [16:48<01:19,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 170/219 - Loss moyenne : 0.2856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 610/657 [16:51<01:16,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 172/219 - Loss moyenne : 0.3143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 612/657 [16:55<01:13,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 174/219 - Loss moyenne : 0.3013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 614/657 [16:58<01:10,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 176/219 - Loss moyenne : 0.3138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 616/657 [17:01<01:07,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 178/219 - Loss moyenne : 0.3051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 618/657 [17:05<01:04,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 180/219 - Loss moyenne : 0.3025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 620/657 [17:08<01:02,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 182/219 - Loss moyenne : 0.3168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 622/657 [17:11<00:59,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 184/219 - Loss moyenne : 0.2805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 624/657 [17:15<00:55,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 186/219 - Loss moyenne : 0.2675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 626/657 [17:18<00:52,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 188/219 - Loss moyenne : 0.3409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 628/657 [17:21<00:48,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 190/219 - Loss moyenne : 0.2894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 630/657 [17:25<00:44,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 192/219 - Loss moyenne : 0.3004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 632/657 [17:28<00:40,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 194/219 - Loss moyenne : 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 634/657 [17:31<00:37,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 196/219 - Loss moyenne : 0.3138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 636/657 [17:34<00:34,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 198/219 - Loss moyenne : 0.2650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 638/657 [17:38<00:30,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200/219 - Loss moyenne : 0.2734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 640/657 [17:41<00:27,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 202/219 - Loss moyenne : 0.2580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 642/657 [17:44<00:24,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 204/219 - Loss moyenne : 0.2882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 644/657 [17:47<00:20,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 206/219 - Loss moyenne : 0.2844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 646/657 [17:50<00:17,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 208/219 - Loss moyenne : 0.3002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 648/657 [17:54<00:14,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 210/219 - Loss moyenne : 0.3010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 650/657 [17:57<00:11,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 212/219 - Loss moyenne : 0.2921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 652/657 [18:00<00:07,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 214/219 - Loss moyenne : 0.2719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 654/657 [18:03<00:04,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 216/219 - Loss moyenne : 0.3066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 656/657 [18:06<00:01,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 218/219 - Loss moyenne : 0.2738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [18:07<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 219/219 - Loss moyenne : 0.1269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('fine_tuned_model/tokenizer_config.json',\n",
       " 'fine_tuned_model/special_tokens_map.json',\n",
       " 'fine_tuned_model/tokenizer.json')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model_lora.train()  # Passer le modèle en mode entraînement\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "torch.cuda.empty_cache()  # Libérer la mémoire inutilisée avant l'entraînement\n",
    "\n",
    "accumulation_steps = 2  # Divise chaque batch en 2 sous-batches\n",
    "running_loss = 0.0  # Variable pour suivre la perte cumulée\n",
    "\n",
    "for epoch in range(3):  # Boucle des époques\n",
    "    print(f\"Époque {epoch + 1}/{3}\")\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        outputs = model_lora(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss = loss / accumulation_steps  # Diviser la perte pour l'accumulation\n",
    "        loss.backward()\n",
    "\n",
    "        running_loss += loss.item()  # Ajouter la perte actuelle à la somme\n",
    "\n",
    "        if (i + 1) % accumulation_steps == 0 or (i + 1) == len(train_dataloader):  # Après accumulation_steps\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Afficher la perte moyenne\n",
    "            avg_loss = running_loss / accumulation_steps\n",
    "            print(f\"Batch {i + 1}/{len(train_dataloader)} - Loss moyenne : {avg_loss:.4f}\")\n",
    "            running_loss = 0.0  # Réinitialiser la perte cumulée\n",
    "\n",
    "        progress_bar.update(1)\n",
    "\n",
    "# Sauvegarde du modèle après l'entraînement\n",
    "model_lora.save_pretrained(\"fine_tuned_model\")\n",
    "tokenizer_lora.save_pretrained(\"fine_tuned_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2538, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement du modèle fine tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "model_lora = PeftModel.from_pretrained(model_lora, \"fine_tuned_model\")\n",
    "tokenizer_lora = AutoTokenizer.from_pretrained(\"fine_tuned_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'PeftModel' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM'].\n"
     ]
    }
   ],
   "source": [
    "LORA_LLM = pipeline(\n",
    "    model=model_lora,\n",
    "    tokenizer=tokenizer_lora,\n",
    "    task=\"text-generation\",\n",
    "    do_sample=True,\n",
    "    temperature=0.2, # Température basse pour la génération\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### B) Modèle de reranking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons également utilisé du reranking. Nous avons utilisé le cross-encoder MiniLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 384)\n",
       "      (token_type_embeddings): Embedding(2, 384)\n",
       "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=384, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chargement du tokenizer et du modèle LLM open source\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer_rerank =  AutoTokenizer.from_pretrained(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "model_rerank = AutoModelForSequenceClassification.from_pretrained(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "model_rerank.eval()  # Passer en mode évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def rerank_with_minilm(question, passage_indices, corpus, model, tokenizer, top_k=4):\n",
    "    \n",
    "    passages = [corpus[idx] for idx in passage_indices]\n",
    "    # Construire les paires (question, passage)\n",
    "    pairs = [(question, passage) for passage in passages]\n",
    "    \n",
    "    # Tokenisation des paires\n",
    "    tokenized_inputs = tokenizer(\n",
    "        [pair[0] for pair in pairs],\n",
    "        [pair[1] for pair in pairs],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "    \n",
    "    # Générer les scores par le modèle\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokenized_inputs)\n",
    "        scores = outputs.logits.squeeze(-1).cpu().numpy()  # Scores de pertinence\n",
    "\n",
    "    # Associer les scores avec les indices globaux des passages\n",
    "    ranked_indices = sorted(\n",
    "        zip(passage_indices, scores), key=lambda x: x[1], reverse=True\n",
    "    )\n",
    "    \n",
    "    # Retourner les indices globaux des top_k passages\n",
    "    return [index for index, score in ranked_indices[:top_k]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### C) Méthode de division de la requête : Sub-queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création des sous-questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm_subquerie =  pipeline(\"text-generation\", model=model_reader,tokenizer=tokenizer_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def generate_subqueries(query, llm, num_queries=3):\n",
    "    \n",
    "    subqueries = []\n",
    "\n",
    "    if len(query) < 40:\n",
    "        num_queries -= 1\n",
    "    \n",
    "    prompt = f\"Your task is only to divide this question [{query}] in maximum {num_queries} differents shorts subquestions names n1,n2 and n3.\"\n",
    "    response = llm(prompt, max_new_tokens=100)\n",
    "    \n",
    "    subqueries= response[0][\"generated_text\"].strip()\n",
    "    subq = re.findall(r\"n\\d+:\\s*(.*?)(?=\\n|$)\", subqueries)\n",
    "    if subq ==[]:\n",
    "        subq = subqueries\n",
    "    return subq[:num_queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "#Val\n",
    "#sub_val = []\n",
    "\n",
    "# for question in val[\"question\"]:\n",
    "#     subqueries = generate_subqueries(question, llm_subquerie, num_queries=3)\n",
    "#     sub_val.append(subqueries)\n",
    "\n",
    "# # sauvegarde\n",
    "# with open('sub_val.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(sub_val, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "#Test \n",
    "#sub_test = []\n",
    "\n",
    "# for question in test[\"question\"]:\n",
    "#     subqueries = generate_subqueries(question, llm_subquerie, num_queries=3)\n",
    "#     sub_test.append(subqueries)\n",
    "\n",
    "# # sauvegarde\n",
    "# with open('sub_test.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(sub_test, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement des sous-questions sauvegardés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sub_val.json', 'r', encoding='utf-8') as f:\n",
    "    sub_val = json.load(f)\n",
    "\n",
    "    \n",
    "with open('sub_test.json', 'r', encoding='utf-8') as f:\n",
    "    sub_test = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the core structure of carbapenems?',\n",
       " 'How does the side chain of carbapenems differ from penicillins?',\n",
       " 'What functional groups are present in carbapenems that are not in penicillins?']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_val[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recherche avec les sous questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "def select_best_documents(results,k):\n",
    "    \n",
    "    # occurrences de chaque document\n",
    "    doc_counts = Counter(results)\n",
    "    \n",
    "    # vote majoritaire\n",
    "    sorted_docs = sorted(doc_counts.items(), key=lambda x: (-x[1], x[0]))  # tri par fréquence, puis par indice\n",
    "    top_docs = [doc[0] for doc in sorted_docs[:k]]\n",
    "\n",
    "    return top_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_passages_subq(questions: list, vector_index: faiss.IndexFlatIP, k: int,\n",
    "                           embedding_model_tokenizer, embedding_model):\n",
    "   \n",
    "    all_indices = []\n",
    "\n",
    "    for subqueries in questions:\n",
    "        #subqueries = generate_subqueries(question, llm_subquerie, num_queries = 3)\n",
    "        results = []\n",
    "        for subquery in subqueries:\n",
    "            \n",
    "            encoded_sub_query = encode_sequences([subquery], embedding_model_tokenizer, embedding_model)\n",
    "            encoded_sub_query = encoded_sub_query.cpu().numpy()\n",
    "        \n",
    "            \n",
    "            dists, idx = vector_index.search(encoded_sub_query, k)\n",
    "            \n",
    "            results.append(idx[0].tolist())\n",
    "        \n",
    "        results = list(chain.from_iterable(results))\n",
    "        \n",
    "        best_indices = select_best_documents(results,k)\n",
    "        \n",
    "        all_indices.append(best_indices)\n",
    "\n",
    "    return all_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### D) Augmentation de la recherche avec Hyde "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_in_chat_format_rewrite = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"Using only the information provided in the context, answer the question.\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Context:\n",
    "{context}\n",
    "---\n",
    "Here is the question you need to develop.\n",
    "\n",
    "Original Question: {question}\"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "RAG_PROMPT_TEMPLATE_REWRITE = tokenizer_reader.apply_chat_template(\n",
    "    prompt_in_chat_format_rewrite, tokenize=False, add_generation_prompt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_passages_hyde(questions: list, vector_index: faiss.IndexFlatIP, k: int,\n",
    "                           embedding_model_tokenizer, embedding_model, corpus):\n",
    "    \n",
    "    all_indices = []\n",
    "\n",
    "    for question in questions:\n",
    "        \n",
    "        # encodage de la requête\n",
    "        encoded_query = encode_sequences([question], embedding_model_tokenizer, embedding_model)\n",
    "        encoded_query = encoded_query.cpu().numpy()\n",
    "        encoded_query /= np.linalg.norm(encoded_query, axis=1, keepdims=True)\n",
    "\n",
    "        # Recherche initiale dans FAISS\n",
    "        dists, indices = vector_index.search(encoded_query, k)\n",
    "        context = \" \".join([corpus[i] for i in indices[0]] if isinstance(corpus, list) else corpus.iloc[indices[0]].tolist())\n",
    "        \n",
    "        # réécriture de la question avec HYDE\n",
    "        question_rw = RAG_PROMPT_TEMPLATE_REWRITE.format(\n",
    "            question=question,\n",
    "            context=context\n",
    "        )\n",
    "        pred_rw = READER_LLM(question_rw)[0][\"generated_text\"]\n",
    "        \n",
    "        question_final =  pred_rw.strip() + question \n",
    "        \n",
    "        # encodage du document hypothétique\n",
    "        encoded_hypothetical = encode_sequences([question_final], embedding_model_tokenizer, embedding_model)\n",
    "        encoded_hypothetical = encoded_hypothetical.cpu().numpy()\n",
    "        \n",
    "\n",
    "        # recherche finale dans l'index FAISS\n",
    "        dists, idx = vector_index.search(encoded_hypothetical, k)\n",
    "        \n",
    "        all_indices.append(idx.tolist()[0])\n",
    "\n",
    "    return all_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### E) Combinaison des documents de Hyde et Sub-queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Combine deux listes en préservant l'ordre et en favorisant les résultats d'une liste via des pondérations.\n",
    "def combine_lists_preserve_order_with_weights(list1, list2, k, weight1=1.0, weight2=1.0):\n",
    "    \n",
    "    scores = defaultdict(float)\n",
    "    \n",
    "    for rank, idx in enumerate(list1):\n",
    "        scores[idx] += weight1 * (1 / (rank + 1))  \n",
    "    \n",
    "    for rank, idx in enumerate(list2):\n",
    "        scores[idx] += weight2 * (1 / (rank + 1))  \n",
    "    \n",
    "    # tri des indices par score décroissant\n",
    "    sorted_indices = sorted(scores.items(), key=lambda x: -x[1])\n",
    "    \n",
    "    top_indices = [idx for idx, score in sorted_indices[:k]]\n",
    "    \n",
    "    return top_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### F) Implémentation complète "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_passages_combined(questions,subs, vector_index, k, embedding_model_tokenizer, embedding_model, corpus,\n",
    "                               gen_tokenizer, gen_model, model_rerank, tokenizer_rerank,n=10):\n",
    "    all_indices = []\n",
    "\n",
    "    for question,subqueries in zip(questions,subs):\n",
    "        \n",
    "        # Méthode HYDE\n",
    "        hyde_indices = retrieve_passages_hyde([question], vector_index, n, embedding_model_tokenizer, embedding_model, corpus)\n",
    "        \n",
    "        # Méthode Sub-Q\n",
    "        subq_indices = retrieve_passages_subq([subqueries], vector_index, n, embedding_model_tokenizer, embedding_model)\n",
    "        \n",
    "        # Combiner les résultats\n",
    "        combined_results = combine_lists_preserve_order_with_weights(hyde_indices[0], subq_indices[0], n,weight1=1.5, weight2=1.0)\n",
    "        \n",
    "        #Reranking -> top k\n",
    "        rerank_indices = rerank_with_minilm(question, combined_results, corpus, model_rerank, tokenizer_rerank, top_k=4)\n",
    "\n",
    "        \n",
    "        all_indices.append(rerank_indices)\n",
    "\n",
    "    return all_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7igy31XlmzR"
   },
   "source": [
    "### 4.4. Évaluation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "RnifBbOPlmzR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "best_4_ids = retrieve_passages_combined(val[\"question\"],sub_val, index, 4, tokenizer, model, text[\"text\"],tokenizer_reader, model_reader, model_rerank, tokenizer_rerank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@4: 0.498\n",
      "Recall@4: 0.7116666666666667\n"
     ]
    }
   ],
   "source": [
    "precisions_4 = compute_precision_at_k(val['text_ids'], best_4_ids)\n",
    "recall_4 = compute_recall_at_k(val['text_ids'], best_4_ids)\n",
    "print(f\"Precision@4: {precisions_4}\")\n",
    "print(f\"Recall@4: {recall_4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_promt= create_prompt_context(val[\"question\"], best_4_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_questions = [ [eval_promt,4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BLEU-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcessing k = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/.venv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/teamspace/studios/this_studio/.venv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/teamspace/studios/this_studio/.venv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "res = evaluate_rag(val,set_questions, LORA_LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu-2 = 0.29649959055100494\n"
     ]
    }
   ],
   "source": [
    "print(f\"Bleu-2 = {res[0][2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwp6bhI_lmzR"
   },
   "source": [
    "### 4.5. Analyse \n",
    "#### 4.5.1. Avantages/limites/Erreurs types \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Notre architecture pour la recherche n'a pas réussi à surpasser significativement le modèle baseline.\n",
    "\n",
    "Le prompt du modèle génératif semble pertinent en augmentant significativement les performances au départ de nos recherches. Le fine-tuning a présenté là aussi une légère amélioration. Il nous semble claire que le goulot d'étranglement réside dans le score de précision qui est très faible. En mettant un k à 4, nous augmentons le rappel mais ajoutant beaucoup de bruits à cause d'une précision faible.  \n",
    "\n",
    "Bien que nous ayons implémenté des techniques visant à enrichir la recherche en obtenant des documents pertinents différents de ceux identifiés par la baseline, nous n'avons pas su combiner ces approches de manière optimale pour améliorer le score de précision.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnjiHOSslmzR"
   },
   "source": [
    "#### 4.5.2. Améliorations potentielles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Pour réduire l'impacte d'une faible précision, il peut être pertinent d'implémenter un juge entrainé sur le training set pour déterminer si la réponse et suffisante. Et ainsi implémenter une itération sur la recherche et génération. Nous avons essayer d'utiliser le modèle génératifs sans affinage comme juge mais il n'était pas performant.\n",
    "\n",
    "Une piste d'amélioration pourrait être un entraînement end-to-end, intégrant à la fois le modèle générant les documents hypothétiques et le modèle d'embedding, afin d'orienter de manière optimale la génération et l'embedding. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0121585c05d245b1a8a6d00a80810020": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75845ea818864a05b6b81d892c918fbb",
      "placeholder": "​",
      "style": "IPY_MODEL_6a0ff00b9fa74d39be07b5171b67ee6d",
      "value": " 181/181 [00:00&lt;00:00, 13.5kB/s]"
     }
    },
    "0231aba660a24c65a17b81c630d20026": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0262d754496d4abe99bedde39a46feff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4221debc451b4befb771ab89469005e4",
      "placeholder": "​",
      "style": "IPY_MODEL_51da695ae4da468799789fa00642f29d",
      "value": "tokenizer.model: 100%"
     }
    },
    "0393be4ac85748c0a566f21810b11797": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04b75b0c26804388a350d07a30ccf372": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_af486d048dbd4201b7fb49e5b7d8b064",
       "IPY_MODEL_aaed6739df41459c83da11f83a4d7831",
       "IPY_MODEL_619558982dc743c6873e0aa35b9cab95"
      ],
      "layout": "IPY_MODEL_673d4896dedf4f7f8e8cdf99496106cb"
     }
    },
    "058e46f1a67848bc84395329d9277d81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0231aba660a24c65a17b81c630d20026",
      "max": 3484,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6fb12bfc3b754744859c5e4957f0cde8",
      "value": 3484
     }
    },
    "0772addcbe7d4940a78d57045df41680": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "07a82338400b49de87e5d3ceed2bac03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07c97b63f17c4079ad617a0106411d77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08fab801a16347fbb6b3760e3a1f213c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_69d82e3ef95547d0bc42fb132ee37fea",
       "IPY_MODEL_36a2190c165340abbd7547b4cac177bd",
       "IPY_MODEL_7f278bceefb84521aa20ed388bbc0ea4"
      ],
      "layout": "IPY_MODEL_dac10bcd070545ac945109b9e586832e"
     }
    },
    "09619988ac094e4c94039d2279e0dfbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e01e9110ece4fda82d6398754dcbbb6",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_14c0a01ee8964f7984cf434fefacc506",
      "value": 231508
     }
    },
    "0b281386c3d24d098198942fce1aee9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c6f5acb28444ac2804e6531231e2f39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0d5856151ab0427e9b1cbb9fa7c75898": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0e2ab26263e24ddeb71e03e23f653163": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0fa84229ff6e4ea8b6221ca9a44b0499": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_79d7239639804379ad3819aab330e1f9",
       "IPY_MODEL_09619988ac094e4c94039d2279e0dfbc",
       "IPY_MODEL_abc39658b8a6406bb3479f66e4591332"
      ],
      "layout": "IPY_MODEL_0393be4ac85748c0a566f21810b11797"
     }
    },
    "10b3a512cdd547099e8edabfed84ccc1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11eff816d23d4f72aa631ff7217a3693": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12f4c1321b814bbea00412916e62eaa2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "134fcf9e6d1b4f7095d83a922353e701": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ee3836da25bf471fb7a3b8fb0f342937",
       "IPY_MODEL_d10b341ed6c34e25a6110f45c2b5f2dc",
       "IPY_MODEL_ee8347d4af2b473289aedfd5d47b0069"
      ],
      "layout": "IPY_MODEL_4e57515c1d0c4e56b9937fb0749ff03d"
     }
    },
    "135b6353dd75494e9e805092efa309dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d7afb8f700124dedade03d5af1ccbcbc",
       "IPY_MODEL_364c6c33f112432abf6622c2ead487bb",
       "IPY_MODEL_b8411a6c8d244047917292330d9e6fd6"
      ],
      "layout": "IPY_MODEL_d0349b79945b49b082c08e831382f033"
     }
    },
    "14b1bc5448a248d6862d595e50f03222": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14c0a01ee8964f7984cf434fefacc506": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "15b245c35bf242a2bd2529024cbe90bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ade4f0035e57486bb66ea68ed8b12d45",
      "placeholder": "​",
      "style": "IPY_MODEL_e916b30ee67947648d62c19e4219b299",
      "value": "config.json: 100%"
     }
    },
    "1ae7f9a1f977494e89b860efafc6d1c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1caf97c36e214739bf381f127c156b47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1fcf72f149a24287a76047d117704bed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1fd82241c79147b89249641b758486c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "212dfbabcc1a43a5aff492d1e2e0a1a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0e2ab26263e24ddeb71e03e23f653163",
      "placeholder": "​",
      "style": "IPY_MODEL_e37915040019425c869d4fcdb0f806b1",
      "value": " 711k/711k [00:00&lt;00:00, 44.9MB/s]"
     }
    },
    "21cf18c5d7004f969ecc12df3379991a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22fc3386dd98456291cbe743c6e9e4b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23af9a14740d4c63ae613788034b6306": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "244aa48ea2c14568877a1d011109a0b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cff71520ea0f47cab63a9b4547ead389",
      "max": 3443,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0772addcbe7d4940a78d57045df41680",
      "value": 3443
     }
    },
    "26060baa46414745922edd51663ce514": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "265e8d73fb8a44dba45ae903ddb0e434": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "27f81e096735470e9134d2291639b35d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c137349e69647938564aa94e080c3fa",
      "placeholder": "​",
      "style": "IPY_MODEL_6b856bebdd7941eebd258243c6e7e0f0",
      "value": " 1.94M/1.94M [00:00&lt;00:00, 16.6MB/s]"
     }
    },
    "29a90894f6434935872673f1d2c5ad6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eab47f2e8b914ef5a2f94299cde9a9c5",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d33cf6b76aaf45fc8b700f8840a7c88b",
      "value": 2
     }
    },
    "2adb0e097d1345c59cedf9b59340b2ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2dad103b367649e392c8cdecab4bb1f0",
      "max": 1937869,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a371bff9659549809531211ade04e6b9",
      "value": 1937869
     }
    },
    "2cb94efd0a214728b10ae033423563cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07c97b63f17c4079ad617a0106411d77",
      "max": 711396,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7e61b106ba36440f8f156255b7d7e8d7",
      "value": 711396
     }
    },
    "2dad103b367649e392c8cdecab4bb1f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30088f44ebb744618ec6a73da82ebded": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32098b40dd55469fa4af3f05c2a38352": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "359ed76056204ec6bdd39735864ede56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c9a62605ea849199b5496f1ce5b40f2",
      "placeholder": "​",
      "style": "IPY_MODEL_8be1e6ccb2c44174828c61b465f09f4f",
      "value": " 2/2 [03:03&lt;00:00, 86.67s/it]"
     }
    },
    "364c6c33f112432abf6622c2ead487bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f37495ff86046f8961220149debbb98",
      "max": 306,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_adfcec3f3afb4ed197d67c38aab09429",
      "value": 306
     }
    },
    "36a2190c165340abbd7547b4cac177bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5298db0fb62b45deaca2ebc8d42a43d4",
      "max": 599,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_993fe4518a084125af1fdb0e1b5f5af9",
      "value": 599
     }
    },
    "37ad66b737f144e59c04ad5cafe914ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38d560a38fac4bc7a8ffe30f80b11f69": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3976b388644c43a4b0cabb927ca02e63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b99f8dc315b4eed814f820c37c4ec70": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3bd94d1a53bc4e968bdbc48f8234e5cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3c137349e69647938564aa94e080c3fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d552f2995d54689a23cf26b3d7b2c56": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f4b1f7416b143fab4aa622255049b25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "411d27a54ed74fbb9190c6a0286caf2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4221debc451b4befb771ab89469005e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "474d7f16e4384284850da8aa31180fc7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "494d02243fcf4717a8ca4ab9a1d86134": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7b0b017442ed44a2afffa945fdc3760f",
       "IPY_MODEL_ce7eb1bc7bb84319afa8066ac5d929c2",
       "IPY_MODEL_f0901fedbe5548f395713b267453156a"
      ],
      "layout": "IPY_MODEL_22fc3386dd98456291cbe743c6e9e4b3"
     }
    },
    "4bc975111b2449ce80bee91afcdeab49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_38d560a38fac4bc7a8ffe30f80b11f69",
      "placeholder": "​",
      "style": "IPY_MODEL_a48e9f06b2434c3cad78a40cc1623966",
      "value": " 743/743 [00:00&lt;00:00, 60.1kB/s]"
     }
    },
    "4d031cce2c7e44eb926164c978e2976c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4d30cfc3292d4f72b6b3c430aa28f97b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e57515c1d0c4e56b9937fb0749ff03d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50241bae59fb4d62aaa601ed65d197da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f96be95ad31461589a26068d6f03a77",
      "placeholder": "​",
      "style": "IPY_MODEL_d94c9ec3e4d146c08cf7bcb130547e1c",
      "value": " 3.44k/3.44k [00:00&lt;00:00, 284kB/s]"
     }
    },
    "506e4a81a6bb402fbc5076922e554c72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "50f6dc7b3bb84eedb5e9977209df0a4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "51da695ae4da468799789fa00642f29d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "520d6abdce0d4f77a71101af317bb1e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5298db0fb62b45deaca2ebc8d42a43d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "552114a8b889485697e484daf03a48e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56d94a63406c423a974726de4a6e451d",
      "placeholder": "​",
      "style": "IPY_MODEL_50f6dc7b3bb84eedb5e9977209df0a4b",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "566f28b2eeb84d08b979c732212cc179": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56d94a63406c423a974726de4a6e451d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5bd0839a7bbd4689b884e83da7872560": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9e153cf6f50a422f8a1aca4edaa4fa0c",
       "IPY_MODEL_817fc0fc03af413a93bf5fc4c73aaac2",
       "IPY_MODEL_a7bb560d04cf48f3a7f1b2c7e9133a68"
      ],
      "layout": "IPY_MODEL_3d552f2995d54689a23cf26b3d7b2c56"
     }
    },
    "5e85e59b59f6445f9f6914abcfc696cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8d52a69c82c948ee8bf96d3e064ceb63",
       "IPY_MODEL_60258885b3734ac6b8db9153e34f0739",
       "IPY_MODEL_4bc975111b2449ce80bee91afcdeab49"
      ],
      "layout": "IPY_MODEL_827325ceb39b4483a0171ff877907cec"
     }
    },
    "600fc4f518ba4078bcf0e3cd9b2b2495": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60258885b3734ac6b8db9153e34f0739": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7aa50c755dd0432a8e7a4a9ef947883f",
      "max": 743,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b010da7e40e9470cae6b964c25573b98",
      "value": 743
     }
    },
    "60585708ae544f3296bafa73f1dc3a80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83eda8c23bec4b258314df9ce6c7fef3",
      "max": 499723,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4d031cce2c7e44eb926164c978e2976c",
      "value": 499723
     }
    },
    "6097d8dd41194e27b4208bcc163ec230": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6d8389172e744cea274082c7d88221e",
      "max": 125,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1fcf72f149a24287a76047d117704bed",
      "value": 125
     }
    },
    "619558982dc743c6873e0aa35b9cab95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0d8a47f8b8e41df8a1dfe0d58fd4fb5",
      "placeholder": "​",
      "style": "IPY_MODEL_8fccabe982914cae816b4646e9eb7dd1",
      "value": " 4.97G/4.97G [01:59&lt;00:00, 42.2MB/s]"
     }
    },
    "61a0576380144b91b149f5c521d158d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ca231ce9920b4c4785e74f7be9c5350c",
       "IPY_MODEL_2adb0e097d1345c59cedf9b59340b2ba",
       "IPY_MODEL_27f81e096735470e9134d2291639b35d"
      ],
      "layout": "IPY_MODEL_aa4a1be513e64426924ae75d41bd3a2a"
     }
    },
    "6339813d2aed49aab357b99859d334d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6601b467bcc146c58f5113f60456cacd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "663923a0b2574caa81af0c326c026e7a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "66f26783d40948d192429c77bfdcf2ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "673d4896dedf4f7f8e8cdf99496106cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6985937a68bb4d79957b8211b1e5388a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b99f8dc315b4eed814f820c37c4ec70",
      "max": 2669692552,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0d5856151ab0427e9b1cbb9fa7c75898",
      "value": 2669692552
     }
    },
    "69b3680cbd724f57b8db313a2b93e514": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69d82e3ef95547d0bc42fb132ee37fea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07a82338400b49de87e5d3ceed2bac03",
      "placeholder": "​",
      "style": "IPY_MODEL_1fd82241c79147b89249641b758486c4",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "6a0ff00b9fa74d39be07b5171b67ee6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6b856bebdd7941eebd258243c6e7e0f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c9a62605ea849199b5496f1ce5b40f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e01e9110ece4fda82d6398754dcbbb6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f37495ff86046f8961220149debbb98": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6fb12bfc3b754744859c5e4957f0cde8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "75845ea818864a05b6b81d892c918fbb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75ebc75a747d4a93b523d82d9ee7ed70": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "777b16dc4a2b4700bf00a0c326f4088a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "791b25855f584a74a97a409e533b41b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79d7239639804379ad3819aab330e1f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_30088f44ebb744618ec6a73da82ebded",
      "placeholder": "​",
      "style": "IPY_MODEL_9e42bead1abb4c738f371445e47aaec2",
      "value": "vocab.txt: 100%"
     }
    },
    "7aa50c755dd0432a8e7a4a9ef947883f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b0b017442ed44a2afffa945fdc3760f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f58d09ee472946b58c3a78efcd252286",
      "placeholder": "​",
      "style": "IPY_MODEL_8d33212e73164f06a52cd0cdb9d2b510",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "7e61b106ba36440f8f156255b7d7e8d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7f278bceefb84521aa20ed388bbc0ea4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_791b25855f584a74a97a409e533b41b4",
      "placeholder": "​",
      "style": "IPY_MODEL_8903451f294140e584100c601dc5167d",
      "value": " 599/599 [00:00&lt;00:00, 54.1kB/s]"
     }
    },
    "7fe4c8115e5b4493aef87524615ea85a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11eff816d23d4f72aa631ff7217a3693",
      "placeholder": "​",
      "style": "IPY_MODEL_df7dfaf2f1bb4f0191cb357dd8be4c53",
      "value": "model-00002-of-00002.safetensors: 100%"
     }
    },
    "817fc0fc03af413a93bf5fc4c73aaac2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_adecbb7a15db476e89ce91326815c67e",
      "max": 16331,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f748dd63b25b480284a15931521a20d1",
      "value": 16331
     }
    },
    "8219e9f52b7446fbbcdec49efa3d4d30": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "827325ceb39b4483a0171ff877907cec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82a7487a0007416e87ac67234acdd3eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b637052dd85d46da91ab0903367fc7c1",
      "placeholder": "​",
      "style": "IPY_MODEL_d5297ca62d4649298f803c7d9860e6c9",
      "value": " 2/2 [00:02&lt;00:00,  1.35s/it]"
     }
    },
    "82fd691d12fc47ec8cdc0b43e69851ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "83eda8c23bec4b258314df9ce6c7fef3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8903451f294140e584100c601dc5167d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8b24846dc0b940eea57733078a627db6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_12f4c1321b814bbea00412916e62eaa2",
      "placeholder": "​",
      "style": "IPY_MODEL_506e4a81a6bb402fbc5076922e554c72",
      "value": " 125/125 [00:00&lt;00:00, 11.3kB/s]"
     }
    },
    "8b4b8b4d34d248c39fbdf08226986624": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8be1e6ccb2c44174828c61b465f09f4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8d33212e73164f06a52cd0cdb9d2b510": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8d52a69c82c948ee8bf96d3e064ceb63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8eb5b8edd1e14ee09f8d501fa3d04c14",
      "placeholder": "​",
      "style": "IPY_MODEL_0c6f5acb28444ac2804e6531231e2f39",
      "value": "config.json: 100%"
     }
    },
    "8eb5b8edd1e14ee09f8d501fa3d04c14": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f45ffa19c9542c6a7f3ae240274f0bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b2cd5263eea54ac9b1e070a088fa314c",
       "IPY_MODEL_2cb94efd0a214728b10ae033423563cc",
       "IPY_MODEL_212dfbabcc1a43a5aff492d1e2e0a1a1"
      ],
      "layout": "IPY_MODEL_37ad66b737f144e59c04ad5cafe914ee"
     }
    },
    "8fccabe982914cae816b4646e9eb7dd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "910760b916c746c99ff2d9bd56afaa92": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91e5cd59d91c424a9126d2cb547ab660": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "97a5e56e0ccb4765ade980dbb81a53e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_910760b916c746c99ff2d9bd56afaa92",
      "max": 181,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_66f26783d40948d192429c77bfdcf2ec",
      "value": 181
     }
    },
    "989f479eeb7b41a4b6895b3b4efdf835": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7fe4c8115e5b4493aef87524615ea85a",
       "IPY_MODEL_6985937a68bb4d79957b8211b1e5388a",
       "IPY_MODEL_e137799f05b24817a2bf65c2a43eb992"
      ],
      "layout": "IPY_MODEL_566f28b2eeb84d08b979c732212cc179"
     }
    },
    "993fe4518a084125af1fdb0e1b5f5af9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9e153cf6f50a422f8a1aca4edaa4fa0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c7b0180ab48249b3ac8ca98e12a33832",
      "placeholder": "​",
      "style": "IPY_MODEL_be79f6b321f64f14bda4c389f7de00e0",
      "value": "model.safetensors.index.json: 100%"
     }
    },
    "9e42bead1abb4c738f371445e47aaec2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9f96be95ad31461589a26068d6f03a77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0338bc56d764ac4a545ca6cc359d166": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0d8a47f8b8e41df8a1dfe0d58fd4fb5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a371bff9659549809531211ade04e6b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a48e9f06b2434c3cad78a40cc1623966": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a4a9a434e6184a84a15d695f59304c3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6339813d2aed49aab357b99859d334d2",
      "placeholder": "​",
      "style": "IPY_MODEL_82fd691d12fc47ec8cdc0b43e69851ca",
      "value": "generation_config.json: 100%"
     }
    },
    "a7bb560d04cf48f3a7f1b2c7e9133a68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb2597d7172a4d8b87da4081d4434bf0",
      "placeholder": "​",
      "style": "IPY_MODEL_f87d77c729814e2dbabf6fd3b4a45fdb",
      "value": " 16.3k/16.3k [00:00&lt;00:00, 1.33MB/s]"
     }
    },
    "aa4a1be513e64426924ae75d41bd3a2a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aaed6739df41459c83da11f83a4d7831": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d16a16915682493aaa6d9808c51b854a",
      "max": 4972489328,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_91e5cd59d91c424a9126d2cb547ab660",
      "value": 4972489328
     }
    },
    "abc39658b8a6406bb3479f66e4591332": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba9e4181a77549feae1aa5d9f4317f91",
      "placeholder": "​",
      "style": "IPY_MODEL_265e8d73fb8a44dba45ae903ddb0e434",
      "value": " 232k/232k [00:00&lt;00:00, 9.22MB/s]"
     }
    },
    "ad1d395ab02b488b8fa42445d4311f86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d4d282b50e9d490f95146540f6a9019f",
       "IPY_MODEL_29a90894f6434935872673f1d2c5ad6f",
       "IPY_MODEL_82a7487a0007416e87ac67234acdd3eb"
      ],
      "layout": "IPY_MODEL_3976b388644c43a4b0cabb927ca02e63"
     }
    },
    "ade4f0035e57486bb66ea68ed8b12d45": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "adecbb7a15db476e89ce91326815c67e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "adfcec3f3afb4ed197d67c38aab09429": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "af486d048dbd4201b7fb49e5b7d8b064": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8b65786ec954c84a4e5570f9267469b",
      "placeholder": "​",
      "style": "IPY_MODEL_a0338bc56d764ac4a545ca6cc359d166",
      "value": "model-00001-of-00002.safetensors: 100%"
     }
    },
    "af9dee883fc44b7289ba4869e641be9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b010da7e40e9470cae6b964c25573b98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b2cd5263eea54ac9b1e070a088fa314c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_520d6abdce0d4f77a71101af317bb1e3",
      "placeholder": "​",
      "style": "IPY_MODEL_d228806adc344076911f2a24e0261016",
      "value": "tokenizer.json: 100%"
     }
    },
    "b3cc9b9c64a24113afdb9cac97d25f2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32098b40dd55469fa4af3f05c2a38352",
      "placeholder": "​",
      "style": "IPY_MODEL_14b1bc5448a248d6862d595e50f03222",
      "value": " 3.48k/3.48k [00:00&lt;00:00, 207kB/s]"
     }
    },
    "b43f843d13514cd9a0172e39d9d3592b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_15b245c35bf242a2bd2529024cbe90bc",
       "IPY_MODEL_058e46f1a67848bc84395329d9277d81",
       "IPY_MODEL_b3cc9b9c64a24113afdb9cac97d25f2a"
      ],
      "layout": "IPY_MODEL_4d30cfc3292d4f72b6b3c430aa28f97b"
     }
    },
    "b60b1f0164204e73b28ae8a2c1595d9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b637052dd85d46da91ab0903367fc7c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6d8389172e744cea274082c7d88221e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8411a6c8d244047917292330d9e6fd6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26060baa46414745922edd51663ce514",
      "placeholder": "​",
      "style": "IPY_MODEL_8b4b8b4d34d248c39fbdf08226986624",
      "value": " 306/306 [00:00&lt;00:00, 27.6kB/s]"
     }
    },
    "ba9e4181a77549feae1aa5d9f4317f91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb2597d7172a4d8b87da4081d4434bf0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc98025f3f7f4ae2a5d5ea6bdf2731be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c54c408e578545d0b8927adc3711eb06",
       "IPY_MODEL_e7c44e300a4c4f6981e12c579a5da52f",
       "IPY_MODEL_359ed76056204ec6bdd39735864ede56"
      ],
      "layout": "IPY_MODEL_6601b467bcc146c58f5113f60456cacd"
     }
    },
    "bddb24c828494cc59fd1cb431907e2da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "be79f6b321f64f14bda4c389f7de00e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c2afad340d0941439b6e795e49054a3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a4a9a434e6184a84a15d695f59304c3a",
       "IPY_MODEL_97a5e56e0ccb4765ade980dbb81a53e4",
       "IPY_MODEL_0121585c05d245b1a8a6d00a80810020"
      ],
      "layout": "IPY_MODEL_1ae7f9a1f977494e89b860efafc6d1c8"
     }
    },
    "c3a219ad044942e19423fa1d306012fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c4a3dae4ccac4c80830b90e40aeff0d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_552114a8b889485697e484daf03a48e2",
       "IPY_MODEL_6097d8dd41194e27b4208bcc163ec230",
       "IPY_MODEL_8b24846dc0b940eea57733078a627db6"
      ],
      "layout": "IPY_MODEL_75ebc75a747d4a93b523d82d9ee7ed70"
     }
    },
    "c54c408e578545d0b8927adc3711eb06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_23af9a14740d4c63ae613788034b6306",
      "placeholder": "​",
      "style": "IPY_MODEL_3f4b1f7416b143fab4aa622255049b25",
      "value": "Downloading shards: 100%"
     }
    },
    "c7b0180ab48249b3ac8ca98e12a33832": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c86be5835b2d4e22b36c67c4f6bdbc18": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ca231ce9920b4c4785e74f7be9c5350c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd47caa8a2304b4a9708f6d3fc2bbdca",
      "placeholder": "​",
      "style": "IPY_MODEL_d594a05b05d64d619f70785f1e0c5474",
      "value": "tokenizer.json: 100%"
     }
    },
    "ce7eb1bc7bb84319afa8066ac5d929c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10b3a512cdd547099e8edabfed84ccc1",
      "max": 366,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_af9dee883fc44b7289ba4869e641be9f",
      "value": 366
     }
    },
    "cf82fa5bc83f4e1889f60bdb25457942": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cfc9a77f379e4f32b8e58fa3ffa664ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cff71520ea0f47cab63a9b4547ead389": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0349b79945b49b082c08e831382f033": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d10b341ed6c34e25a6110f45c2b5f2dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21cf18c5d7004f969ecc12df3379991a",
      "max": 133466304,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e212d76cc0e44b0691b8584c2d7ea10f",
      "value": 133466304
     }
    },
    "d16a16915682493aaa6d9808c51b854a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d228806adc344076911f2a24e0261016": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d33cf6b76aaf45fc8b700f8840a7c88b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d4d282b50e9d490f95146540f6a9019f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f1e77d1e6f564f22af7855b4c5403382",
      "placeholder": "​",
      "style": "IPY_MODEL_1caf97c36e214739bf381f127c156b47",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "d5297ca62d4649298f803c7d9860e6c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d53361106b504cb7a0dbe33d0e9f9cd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d594a05b05d64d619f70785f1e0c5474": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d7afb8f700124dedade03d5af1ccbcbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8219e9f52b7446fbbcdec49efa3d4d30",
      "placeholder": "​",
      "style": "IPY_MODEL_411d27a54ed74fbb9190c6a0286caf2f",
      "value": "added_tokens.json: 100%"
     }
    },
    "d94c9ec3e4d146c08cf7bcb130547e1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dac10bcd070545ac945109b9e586832e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db434b2cacb943779dd5f273f5ac00b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b281386c3d24d098198942fce1aee9e",
      "placeholder": "​",
      "style": "IPY_MODEL_c86be5835b2d4e22b36c67c4f6bdbc18",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "dd47caa8a2304b4a9708f6d3fc2bbdca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df7dfaf2f1bb4f0191cb357dd8be4c53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e0629709cb8d464588012a1faa11157f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_db434b2cacb943779dd5f273f5ac00b8",
       "IPY_MODEL_244aa48ea2c14568877a1d011109a0b4",
       "IPY_MODEL_50241bae59fb4d62aaa601ed65d197da"
      ],
      "layout": "IPY_MODEL_777b16dc4a2b4700bf00a0c326f4088a"
     }
    },
    "e137799f05b24817a2bf65c2a43eb992": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f60deb43aa074d009f2fb0ee36a46852",
      "placeholder": "​",
      "style": "IPY_MODEL_d53361106b504cb7a0dbe33d0e9f9cd3",
      "value": " 2.67G/2.67G [01:03&lt;00:00, 42.3MB/s]"
     }
    },
    "e212d76cc0e44b0691b8584c2d7ea10f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e2e6d0a35eba4f3d90a49c14def54ae4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e37915040019425c869d4fcdb0f806b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e7c44e300a4c4f6981e12c579a5da52f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_474d7f16e4384284850da8aa31180fc7",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bddb24c828494cc59fd1cb431907e2da",
      "value": 2
     }
    },
    "e916b30ee67947648d62c19e4219b299": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eab47f2e8b914ef5a2f94299cde9a9c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee3836da25bf471fb7a3b8fb0f342937": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2e6d0a35eba4f3d90a49c14def54ae4",
      "placeholder": "​",
      "style": "IPY_MODEL_3bd94d1a53bc4e968bdbc48f8234e5cf",
      "value": "model.safetensors: 100%"
     }
    },
    "ee8347d4af2b473289aedfd5d47b0069": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_600fc4f518ba4078bcf0e3cd9b2b2495",
      "placeholder": "​",
      "style": "IPY_MODEL_b60b1f0164204e73b28ae8a2c1595d9e",
      "value": " 133M/133M [00:00&lt;00:00, 192MB/s]"
     }
    },
    "f0901fedbe5548f395713b267453156a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_663923a0b2574caa81af0c326c026e7a",
      "placeholder": "​",
      "style": "IPY_MODEL_c3a219ad044942e19423fa1d306012fc",
      "value": " 366/366 [00:00&lt;00:00, 30.0kB/s]"
     }
    },
    "f1e77d1e6f564f22af7855b4c5403382": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f37c13a1e38a4ba8a9ad70eddcc4ee7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0262d754496d4abe99bedde39a46feff",
       "IPY_MODEL_60585708ae544f3296bafa73f1dc3a80",
       "IPY_MODEL_fef3cf511e7e465f8f083641325e6ffb"
      ],
      "layout": "IPY_MODEL_69b3680cbd724f57b8db313a2b93e514"
     }
    },
    "f58d09ee472946b58c3a78efcd252286": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f60deb43aa074d009f2fb0ee36a46852": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f748dd63b25b480284a15931521a20d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f87d77c729814e2dbabf6fd3b4a45fdb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f8b65786ec954c84a4e5570f9267469b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fef3cf511e7e465f8f083641325e6ffb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf82fa5bc83f4e1889f60bdb25457942",
      "placeholder": "​",
      "style": "IPY_MODEL_cfc9a77f379e4f32b8e58fa3ffa664ca",
      "value": " 500k/500k [00:00&lt;00:00, 32.7MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
